# title: è¿›åº¦è¿½è¸ª

import streamlit as st
import pandas as pd
import altair as alt
from datetime import datetime
from typing import List, Dict, Optional
import io
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥config
sys.path.insert(0, str(Path(__file__).parent.parent))
from config import DEFAULT_DATA_FOLDER, WIP_REPORT_KEYWORDS

APP_ROOT = Path(__file__).resolve().parent.parent


def resolve_input_path(path_str: str) -> Path:
    """Resolve user-provided folder path, supporting relative inputs like ./data."""
    normalized = path_str.strip()
    if not normalized:
        raise ValueError("è·¯å¾„ä¸èƒ½ä¸ºç©º")

    candidate = Path(normalized).expanduser()
    if not candidate.is_absolute():
        candidate = APP_ROOT / candidate
    return candidate.resolve()


# å®šä¹‰æ‰€æœ‰ç«™åˆ«ï¼ˆæŒ‰å·¥è‰ºæµç¨‹é¡ºåºï¼‰- åŸºç¡€ç«™åˆ«
BASE_STATIONS = [
    "æ‰“æ ‡", "æ¸…æ´—", "å£³ä½“ç»„è£…", "å›æµ", "facå‰å¤‡æ–™", "æ‰“çº¿", "fac", "facè¡¥èƒ¶", 
    "facè¡¥èƒ¶åçƒ˜çƒ¤", "facæµ‹è¯•", "sacç»„è£…", "å…‰çº¤ç»„è£…", "å…‰çº¤ç»„è£…åçƒ˜çƒ¤", 
    "çº¢å…‰è€¦åˆ", "è£…å¤§å", "çº¢å…‰è€¦åˆåçƒ˜çƒ¤", "åˆæŸ", "åˆæŸåçƒ˜çƒ¤", 
    "NAå‰é•œæ£€", "NAå‰çº¢å…‰ç«¯é¢æ£€", "NAæµ‹è¯•", "è€¦åˆæµ‹è¯•", "è¡¥èƒ¶", "æ¸©åº¦å¾ªç¯", 
    "Preæµ‹è¯•", "ä½æ¸©å­˜å‚¨", "ä½æ¸©å­˜å‚¨åæµ‹è¯•", "é«˜æ¸©å­˜å‚¨", "é«˜æ¸©å­˜å‚¨åæµ‹è¯•", 
    "è€åŒ–å‰çº¢å…‰ç«¯é¢", "postæµ‹è¯•", "çº¢å…‰ç«¯é¢æ£€æŸ¥", "é•œæ£€", "å°ç›–", "å°ç›–æµ‹è¯•", 
    "åˆ†çº§", "å…¥åº“æ£€", "å…¥åº“", "RMA"
]

def get_stations_for_part(part_number: str) -> list:
    """æ ¹æ®æ–™å·è¿”å›é€‚ç”¨çš„ç«™åˆ«åˆ—è¡¨"""
    stations = BASE_STATIONS.copy()
    
    # å¦‚æœæ–™å·åŒ…å«Vï¼Œåœ¨åˆæŸåçƒ˜çƒ¤åé¢æ’å…¥VBGå’ŒVBGåçƒ˜çƒ¤
    if 'V' in str(part_number).upper():
        hesu_idx = stations.index("åˆæŸåçƒ˜çƒ¤")
        stations.insert(hesu_idx + 1, "VBG")
        stations.insert(hesu_idx + 2, "VBGåçƒ˜çƒ¤")
    
    # æ·»åŠ "å·²å®Œæˆ"ä½œä¸ºæœ€åä¸€ä¸ªç«™åˆ«
    stations.append("å·²å®Œæˆ")
    
    return stations

# ç«™åˆ«æ˜ å°„ï¼ˆExcelåˆ—ååˆ°æ ‡å‡†ç«™åˆ«åï¼‰
STATION_MAPPING = {
    "æœºæ¢°ä»¶æ‰“æ ‡": "æ‰“æ ‡",
    "æœºæ¢°ä»¶æ¸…æ´—": "æ¸…æ´—",
    "å£³ä½“ç»„è£…": "å£³ä½“ç»„è£…",
    "å…‰è€¦å›æµ": "å›æµ",
    "FACå‰å¤‡æ–™": "facå‰å¤‡æ–™",
    "æ‰“çº¿": "æ‰“çº¿",
    "FAC": "fac",
    "FACè¡¥èƒ¶": "facè¡¥èƒ¶",
    "FACè¡¥èƒ¶åçƒ˜çƒ¤": "facè¡¥èƒ¶åçƒ˜çƒ¤",
    "FACæµ‹è¯•": "facæµ‹è¯•",
    "SACç»„è£…": "sacç»„è£…",
    "å…‰çº¤ç»„è£…": "å…‰çº¤ç»„è£…",
    "å…‰çº¤ç»„è£…åçƒ˜çƒ¤": "å…‰çº¤ç»„è£…åçƒ˜çƒ¤",
    "çº¢å…‰è€¦åˆ": "çº¢å…‰è€¦åˆ",
    "è£…å¤§å": "è£…å¤§å",
    "è€¦åˆåçƒ˜çƒ¤": "çº¢å…‰è€¦åˆåçƒ˜çƒ¤",
    "çº¢å…‰è€¦åˆåçƒ˜çƒ¤": "çº¢å…‰è€¦åˆåçƒ˜çƒ¤",
    "åˆæŸ": "åˆæŸ",
    "åˆæŸåçƒ˜çƒ¤": "åˆæŸåçƒ˜çƒ¤",
    "VBG": "VBG",
    "VBGåçƒ˜çƒ¤": "VBGåçƒ˜çƒ¤",
    "NAå‰é•œæ£€": "NAå‰é•œæ£€",
    "NAå‰çº¢å…‰ç«¯é¢æ£€": "NAå‰çº¢å…‰ç«¯é¢æ£€",
    "NAå‰çº¢å…‰ç«¯é¢æ£€æŸ¥": "NAå‰çº¢å…‰ç«¯é¢æ£€",
    "NAæµ‹è¯•": "NAæµ‹è¯•",
    "è€¦åˆæµ‹è¯•": "è€¦åˆæµ‹è¯•",
    "è¡¥èƒ¶": "è¡¥èƒ¶",
    "æ¸©åº¦å¾ªç¯": "æ¸©åº¦å¾ªç¯",
    "preæµ‹è¯•": "Preæµ‹è¯•",
    "Preæµ‹è¯•": "Preæµ‹è¯•",
    "ä½æ¸©å­˜å‚¨": "ä½æ¸©å­˜å‚¨",
    "ä½æ¸©å‚¨å­˜": "ä½æ¸©å­˜å‚¨",
    "ä½æ¸©å­˜å‚¨åæµ‹è¯•": "ä½æ¸©å­˜å‚¨åæµ‹è¯•",
    "ä½æ¸©å‚¨å­˜åæµ‹è¯•": "ä½æ¸©å­˜å‚¨åæµ‹è¯•",
    "é«˜æ¸©å­˜å‚¨": "é«˜æ¸©å­˜å‚¨",
    "é«˜æ¸©å­˜å‚¨åæµ‹è¯•": "é«˜æ¸©å­˜å‚¨åæµ‹è¯•",
    "è€åŒ–": "è€åŒ–å‰çº¢å…‰ç«¯é¢",
    "è€åŒ–å‰çº¢å…‰ç«¯é¢": "è€åŒ–å‰çº¢å…‰ç«¯é¢",
    "è€åŒ–å‰çº¢å…‰ç«¯é¢æ£€æŸ¥": "è€åŒ–å‰çº¢å…‰ç«¯é¢",
    "postæµ‹è¯•": "postæµ‹è¯•",
    "Postæµ‹è¯•": "postæµ‹è¯•",
    "çº¢å…‰ç«¯é¢æ£€æŸ¥": "çº¢å…‰ç«¯é¢æ£€æŸ¥",
    "é•œæ£€": "é•œæ£€",
    "å°ç›–": "å°ç›–",
    "å°ç›–æµ‹è¯•": "å°ç›–æµ‹è¯•",
    "é¡¶ç›–": "å°ç›–",
    "é¡¶ç›–æµ‹è¯•": "å°ç›–æµ‹è¯•",
    "åˆ†çº§": "åˆ†çº§",
    "å…¥åº“æ£€": "å…¥åº“æ£€",
    "å…¥åº“--å…‰è€¦": "å…¥åº“",
    "å…¥åº“": "å…¥åº“",
    "å¾…å…¥åº“": "å…¥åº“",
    "RMAæ€§èƒ½æµ‹è¯•": "RMA",
    "RMAæ‹†ç›–æ£€æŸ¥": "RMA",
    "RMA": "RMA",
    "æ‹†è§£": "å·¥ç¨‹åˆ†æ",
    "æœªå¼€å§‹": "æœªå¼€å§‹",
    "å·²å®Œæˆ": "å·²å®Œæˆ",
    "complete": "å·²å®Œæˆ",
    "COMPLETE": "å·²å®Œæˆ",
    "TERMINATED": "å·²å®Œæˆ",
    "å®Œæˆ": "å·²å®Œæˆ"
}

STATION_MAPPING_LOWER = {key.lower(): value for key, value in STATION_MAPPING.items()}
BASE_STATIONS_LOWER = {station.lower(): station for station in BASE_STATIONS}

PRODUCTION_ORDER_CANDIDATES: List[str] = [
    "ç”Ÿäº§è®¢å•",
    "ERPç”Ÿäº§è®¢å•",
    "SAPç”Ÿäº§è®¢å•",
    "ç”Ÿäº§è®¢å•å·",
    "è®¢å•å·",
    "å·¥å•å·",
]

def parse_uploaded_file(uploaded_file) -> Optional[pd.DataFrame]:
    """è§£æä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xls', '.xlsx')):
            df = pd.read_excel(uploaded_file)
        else:
            st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶")
            return None
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
        return None

def normalize_station_name(station_name: str) -> str:
    """å°†Excelä¸­çš„ç«™åˆ«åç§°æ ‡å‡†åŒ–ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰"""
    if pd.isna(station_name) or station_name == '':
        return ''

    station_name = str(station_name).strip()
    station_name_lower = station_name.lower()

    # åŒ…å« rma å­—æ ·çš„éƒ½å½’åˆ° RMA ç«™åˆ«
    if 'rma' in station_name_lower:
        return 'RMA'

    # ç›´æ¥æ˜ å°„ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
    if station_name_lower in STATION_MAPPING_LOWER:
        return STATION_MAPPING_LOWER[station_name_lower]

    # å°è¯•å»æ‰"æµ‹è¯•"åç¼€
    if station_name.endswith('æµ‹è¯•') or station_name_lower.endswith('æµ‹è¯•'):
        base_name = station_name[:-2]
        base_name_lower = base_name.lower()
        if base_name_lower in STATION_MAPPING_LOWER:
            return STATION_MAPPING_LOWER[base_name_lower]

    # å°è¯•æ·»åŠ "æµ‹è¯•"åç¼€
    test_name_lower = station_name_lower + 'æµ‹è¯•'
    if test_name_lower in STATION_MAPPING_LOWER:
        return STATION_MAPPING_LOWER[test_name_lower]

    # å°è¯•åœ¨BASE_STATIONSä¸­æŸ¥æ‰¾ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
    if station_name_lower in BASE_STATIONS_LOWER:
        return BASE_STATIONS_LOWER[station_name_lower]

    # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
    clean_name = station_name_lower.replace(' ', '').replace('-', '').replace('_', '')
    for key, value in STATION_MAPPING_LOWER.items():
        clean_key = key.replace(' ', '').replace('-', '').replace('_', '')
        if clean_name == clean_key:
            return value
   
    # è¿”å›åŸå§‹åç§°
    return station_name

def extract_progress_data(df: pd.DataFrame) -> pd.DataFrame:
    """ä»åŸå§‹æ•°æ®ä¸­æå–è¿›åº¦ä¿¡æ¯"""
    progress_data = []
    unrecognized_stations = set()
    
    column_lookup = {str(col).strip(): col for col in df.columns}
    production_order_column = next(
        (column_lookup[name] for name in PRODUCTION_ORDER_CANDIDATES if name in column_lookup),
        None,
    )
    
    for _, row in df.iterrows():
        shell_id = row.get('å£³ä½“å·', '')
        if pd.isna(shell_id) or shell_id == '':
            continue
        shell_id = str(shell_id).strip()
        
        part_number_value = row.get('æ–™å·', '')
        if production_order_column is not None and production_order_column in row.index:
            production_order_value = row.get(production_order_column, '')
        else:
            production_order_value = row.get('ç”Ÿäº§è®¢å•', '')
        part_number = "" if pd.isna(part_number_value) else str(part_number_value).strip()
        production_order = "" if pd.isna(production_order_value) else str(production_order_value).strip()
        
        current_station_raw = row.get('å½“å‰ç«™ç‚¹', '')
        current_station = normalize_station_name(current_station_raw)
        
        # æ”¶é›†æœªè¯†åˆ«çš„ç«™åˆ«
        if (
            current_station_raw
            and current_station == current_station_raw
            and current_station not in BASE_STATIONS
            and current_station not in {'å·¥ç¨‹åˆ†æ', 'å·²å®Œæˆ', 'æœªå¼€å§‹'}
        ):
            unrecognized_stations.add(current_station_raw)
        
        shell_progress = {
            'å£³ä½“å·': shell_id,
            'æ–™å·': part_number,
            'ç”Ÿäº§è®¢å•': production_order,
            'å½“å‰ç«™ç‚¹': current_station,
            'å½“å‰ç«™ç‚¹åŸå§‹': current_station_raw,
            'ä¸Šä¸€ç«™': row.get('ä¸Šä¸€ç«™', ''),
            'å®Œæˆç«™åˆ«': [],
            'ç«™åˆ«æ—¶é—´': {},
            'æ˜¯å¦å·¥ç¨‹åˆ†æ': current_station == 'å·¥ç¨‹åˆ†æ'
        }

        station_time_mapping: Dict[str, object] = {}
        
        # æ£€æŸ¥æ‰€æœ‰ç«™åˆ«çš„æ—¶é—´åˆ—
        for excel_col, standard_station in STATION_MAPPING.items():
            time_col = f"{excel_col}æ—¶é—´"
            if time_col in df.columns:
                time_value = row.get(time_col)
                if pd.notna(time_value) and str(time_value).strip():
                    shell_progress['å®Œæˆç«™åˆ«'].append(standard_station)
                    station_time_mapping[standard_station] = time_value
        
        shell_progress['ç«™åˆ«æ—¶é—´'] = station_time_mapping
        
        progress_data.append(shell_progress)
    
    # å¦‚æœæœ‰æœªè¯†åˆ«çš„ç«™åˆ«ï¼Œæ˜¾ç¤ºè­¦å‘Š
    if unrecognized_stations:
        st.warning(f"âš ï¸ å‘ç°æœªè¯†åˆ«çš„ç«™åˆ«åç§°: {', '.join(sorted(unrecognized_stations))}")
    
    result_df = pd.DataFrame(progress_data)
    result_df.attrs["production_order_column"] = production_order_column
    
    return result_df

def calculate_station_counts(progress_df: pd.DataFrame) -> pd.DataFrame:
    """ç»Ÿè®¡å„å½“å‰ç«™åˆ«çš„å£³ä½“æ•°é‡ä¸å æ¯”"""
    if progress_df.empty:
        return pd.DataFrame(columns=["ç«™åˆ«", "æ•°é‡", "å æ¯”"])

    unknown_label = "æœªè¯†åˆ«"
    station_series = (
        progress_df["å½“å‰ç«™ç‚¹"]
        .fillna("")
        .astype(str)
        .str.strip()
    )
    station_series = station_series.replace({"": unknown_label, "nan": unknown_label})
    station_series = station_series.apply(
        lambda value: normalize_station_name(value) if value != unknown_label else value
    )

    counts = station_series.value_counts(dropna=False).reset_index()
    counts.columns = ["ç«™åˆ«", "æ•°é‡"]
    counts["å æ¯”"] = counts["æ•°é‡"] / len(progress_df)

    # RMA å·²ç»åœ¨ BASE_STATIONS ä¸­ï¼Œå·¥ç¨‹åˆ†ææ”¾åœ¨æœ€å
    ordered_labels = BASE_STATIONS + ["å·¥ç¨‹åˆ†æ", "å·²å®Œæˆ", unknown_label]
    order_map = {label: idx for idx, label in enumerate(ordered_labels)}
    counts["æ’åº"] = counts["ç«™åˆ«"].map(order_map)

    fallback_order = len(ordered_labels) + counts.index.to_series()
    counts["æ’åº"] = counts["æ’åº"].fillna(fallback_order)

    counts = counts.sort_values(["æ’åº", "ç«™åˆ«"]).drop(columns="æ’åº").reset_index(drop=True)

    return counts

def create_gantt_chart(progress_df: pd.DataFrame) -> alt.Chart:
    """åˆ›å»ºç”˜ç‰¹å›¾ï¼ˆä½¿ç”¨ Altairï¼‰"""
    # è¿‡æ»¤æ‰å·²å®Œæˆçš„å£³ä½“
    progress_df = progress_df[progress_df.get('å½“å‰ç«™ç‚¹', '') != 'å·²å®Œæˆ'].copy()
    
    # å‡†å¤‡ç”˜ç‰¹å›¾æ•°æ®
    gantt_data = []

    def format_time_value(value: object) -> str:
        """å°†åŸå§‹æ—¶é—´å€¼æ ¼å¼åŒ–ä¸ºç»Ÿä¸€çš„å±•ç¤ºå­—ç¬¦ä¸²"""
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return "--"
        if isinstance(value, pd.Timestamp):
            return value.strftime("%m-%d %H:%M")
        if isinstance(value, datetime):
            return value.strftime("%m-%d %H:%M")
        if hasattr(value, "strftime"):
            try:
                return value.strftime("%m-%d %H:%M")
            except Exception:  # pragma: no cover - å®¹é”™å¤„ç†
                pass
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return "--"
            parsed = pd.to_datetime(stripped, errors="coerce")
            if pd.notna(parsed):
                return parsed.strftime("%m-%d %H:%M")
            return stripped
        if isinstance(value, (int, float)):
            if pd.isna(value):
                return "--"
            parsed_excel = pd.NaT
            base_date = pd.Timestamp("1899-12-30")
            try:
                parsed_excel = base_date + pd.to_timedelta(float(value), unit="D")
            except Exception:  # pragma: no cover - å®¹é”™å¤„ç†
                parsed_excel = pd.NaT
            if pd.notna(parsed_excel):
                return parsed_excel.strftime("%m-%d %H:%M")
            parsed = pd.NaT
            try:
                parsed = pd.to_datetime(value)
            except Exception:  # pragma: no cover - å®¹é”™å¤„ç†
                parsed = pd.NaT
            if pd.notna(parsed):
                return parsed.strftime("%m-%d %H:%M")
            return str(value)
        return str(value)

    # æ”¶é›†æ‰€æœ‰éœ€è¦æ˜¾ç¤ºçš„ç«™åˆ«ï¼ˆåŒ…æ‹¬VBGå’Œå·¥ç¨‹åˆ†æï¼‰
    all_stations_set = set()
    
    for idx, row in progress_df.iterrows():
        shell_id = row['å£³ä½“å·']
        part_number = row.get('æ–™å·', '')
        completed_stations = row['å®Œæˆç«™åˆ«']
        current_station = row.get('å½“å‰ç«™ç‚¹', '')
        is_engineering = row.get('æ˜¯å¦å·¥ç¨‹åˆ†æ', False)
        station_times = row.get('ç«™åˆ«æ—¶é—´', {})
        if not isinstance(station_times, dict):
            station_times = {}
        
        # è·å–è¯¥æ–™å·é€‚ç”¨çš„ç«™åˆ«åˆ—è¡¨
        stations = get_stations_for_part(part_number)
        
        all_stations_set.update(stations)
        
        # å¦‚æœæ˜¯å·¥ç¨‹åˆ†æï¼Œæ‰¾åˆ°ä¸Šä¸€ç«™çš„ç´¢å¼•
        last_station_idx = -1
        if is_engineering:
            # è·å–ä¸Šä¸€ç«™
            last_station = row.get('ä¸Šä¸€ç«™', '')
            # æ ‡å‡†åŒ–ä¸Šä¸€ç«™åç§°
            last_station_normalized = normalize_station_name(last_station)
            if last_station_normalized and last_station_normalized in stations:
                last_station_idx = stations.index(last_station_normalized)
        
        # æ£€æŸ¥æ˜¯å¦ä¸º RMA ç«™åˆ«
        is_rma = (current_station == "RMA")
        
        # æ‰¾åˆ°å½“å‰ç«™ç‚¹çš„ç´¢å¼•ä½ç½®ï¼ˆéå·¥ç¨‹åˆ†æå’ŒéRMAçš„æƒ…å†µï¼‰
        current_station_idx = -1
        if not is_engineering and not is_rma and current_station and current_station in stations:
            current_station_idx = stations.index(current_station)
        
        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾"å·²å®Œæˆ"ç«™åˆ«
        is_fully_completed = (current_station == "å·²å®Œæˆ")
        
        for station_idx, station in enumerate(stations):
            # åˆ¤æ–­çŠ¶æ€çš„é€»è¾‘
            if is_engineering:
                # å·¥ç¨‹åˆ†æï¼šä¸Šä¸€ç«™åŠä¹‹å‰çš„éƒ½æ ‡è®°ä¸ºå·¥ç¨‹åˆ†æï¼ˆçº¢è‰²ï¼‰
                if last_station_idx >= 0 and station_idx <= last_station_idx:
                    status = "å·²å®Œæˆ"
                    is_engineering_cell = True
                else:
                    status = "æœªå¼€å§‹"
                    is_engineering_cell = False
            elif is_rma:
                # RMAï¼šæ•´è¡Œéƒ½æ ‡è®°ä¸º RMA çŠ¶æ€
                status = "RMA"
                is_engineering_cell = False
            elif is_fully_completed:
                # å¦‚æœå½“å‰ç«™ç‚¹æ˜¯"å·²å®Œæˆ"ï¼Œæ•´è¡Œéƒ½æ ‡è®°ä¸ºå…¨éƒ¨å®Œæˆï¼ˆå…¨ç»¿ï¼‰
                status = "å…¨éƒ¨å®Œæˆ"
                is_engineering_cell = False
            else:
                # æ­£å¸¸æƒ…å†µï¼š
                # 1. å½“å‰ç«™ç‚¹å°±æ˜¯è¿›è¡Œä¸­ï¼ˆçº¢è‰²ï¼‰
                # 2. å½“å‰ç«™ç‚¹ä¹‹å‰çš„éƒ½æ˜¯å·²å®Œæˆï¼ˆæ·±ç°ï¼‰
                # 3. å½“å‰ç«™ç‚¹ä¹‹åçš„éƒ½æ˜¯æœªå¼€å§‹ï¼ˆæµ…ç°ï¼‰
                is_engineering_cell = False
                if current_station_idx >= 0:
                    if station_idx < current_station_idx:
                        status = "å·²å®Œæˆ"
                    elif station_idx == current_station_idx:
                        status = "è¿›è¡Œä¸­"
                    else:
                        status = "æœªå¼€å§‹"
                else:
                    # å¦‚æœæ²¡æœ‰å½“å‰ç«™ç‚¹ä¿¡æ¯ï¼Œæ ¹æ®å®Œæˆæ—¶é—´åˆ¤æ–­
                    if station in completed_stations:
                        status = "å·²å®Œæˆ"
                    else:
                        status = "æœªå¼€å§‹"

            time_value = station_times.get(station)
            time_source_station = station
            if (time_value is None or (isinstance(time_value, str) and not time_value.strip())) and status == "è¿›è¡Œä¸­":
                for prev_idx in range(station_idx - 1, -1, -1):
                    prev_station = stations[prev_idx]
                    prev_value = station_times.get(prev_station)
                    if prev_value is not None:
                        time_value = prev_value
                        time_source_station = prev_station
                        break

            time_display = format_time_value(time_value)
            if time_display != "--" and time_source_station != station:
                time_display = f"{time_display}ï¼ˆä¸Šä¸€ç«™ï¼š{time_source_station}ï¼‰"

            gantt_data.append({
                'å£³ä½“å·': shell_id,
                'ç«™åˆ«': station,
                'ç«™åˆ«åºå·': station_idx,
                'çŠ¶æ€': status,
                'æ˜¯å¦å·¥ç¨‹åˆ†æå•å…ƒæ ¼': is_engineering_cell,
                'ç«™åˆ«æ—¶é—´': time_display
            })
    
    gantt_df = pd.DataFrame(gantt_data)
    
    # åˆ›å»ºæ‰€æœ‰ç«™åˆ«çš„æ’åºåˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬å·¥ç¨‹åˆ†æï¼‰
    all_stations_sorted = BASE_STATIONS.copy()
    if 'VBG' in all_stations_set:
        hesu_idx = all_stations_sorted.index("åˆæŸåçƒ˜çƒ¤")
        all_stations_sorted.insert(hesu_idx + 1, "VBG")
        all_stations_sorted.insert(hesu_idx + 2, "VBGåçƒ˜çƒ¤")
    # æ·»åŠ "å·²å®Œæˆ"ä½œä¸ºæœ€åä¸€ä¸ªç«™åˆ«
    all_stations_sorted.append("å·²å®Œæˆ")
    
    # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
    color_scale = alt.Scale(
        domain=['æœªå¼€å§‹', 'è¿›è¡Œä¸­', 'å·²å®Œæˆ'],
        range=['#bdc3c7', '#f1c40f', '#2ecc71']  # ç°è‰²ã€é»„è‰²ã€ç»¿è‰²
    )
    
    # ä¸ºæ¯ä¸ªå£³ä½“è®¡ç®—å½“å‰ç«™åˆ«çš„åºå·ï¼ˆç”¨äºæ’åºï¼‰
    shell_station_order = {}
    for shell_id in gantt_df['å£³ä½“å·'].unique():
        shell_data = gantt_df[gantt_df['å£³ä½“å·'] == shell_id]
        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼Œæ’åœ¨æœ€ä¸Šé¢ï¼‰
        fully_completed = shell_data[shell_data['çŠ¶æ€'] == 'å…¨éƒ¨å®Œæˆ']
        if not fully_completed.empty:
            shell_station_order[shell_id] = 99999  # ä½¿ç”¨æœ€å¤§å€¼è®©å…¨éƒ¨å®Œæˆçš„æ’åœ¨æœ€ä¸Šé¢
        else:
            # æ£€æŸ¥æ˜¯å¦ä¸º RMA çŠ¶æ€
            rma_status = shell_data[shell_data['çŠ¶æ€'] == 'RMA']
            if not rma_status.empty:
                # RMA ä½¿ç”¨ä¸€ä¸ªè¾ƒå¤§çš„åºå·ï¼Œæ’åœ¨æ­£å¸¸æµç¨‹ä¹‹å
                shell_station_order[shell_id] = 90000
            else:
                # æ‰¾åˆ°è¿›è¡Œä¸­çš„ç«™åˆ«åºå·ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨å·²å®Œæˆçš„æœ€å¤§åºå·
                in_progress = shell_data[shell_data['çŠ¶æ€'] == 'è¿›è¡Œä¸­']
                if not in_progress.empty:
                    shell_station_order[shell_id] = in_progress.iloc[0]['ç«™åˆ«åºå·']
                else:
                    completed = shell_data[shell_data['çŠ¶æ€'] == 'å·²å®Œæˆ']
                    if not completed.empty:
                        shell_station_order[shell_id] = completed['ç«™åˆ«åºå·'].max()
                    else:
                        shell_station_order[shell_id] = -1
    
    # æ·»åŠ æ’åºå­—æ®µåˆ°æ•°æ®æ¡†
    gantt_df['å£³ä½“æ’åºåºå·'] = gantt_df['å£³ä½“å·'].map(shell_station_order)
    
    # ä¸ºå·¥ç¨‹åˆ†æå•å…ƒæ ¼æ·»åŠ ç‰¹æ®ŠçŠ¶æ€æ ‡è¯†
    gantt_df['æ˜¾ç¤ºçŠ¶æ€'] = gantt_df.apply(
        lambda row: 'å·¥ç¨‹åˆ†æ' if row['æ˜¯å¦å·¥ç¨‹åˆ†æå•å…ƒæ ¼'] else row['çŠ¶æ€'],
        axis=1
    )
    
    # å®šä¹‰åŒ…å«å·¥ç¨‹åˆ†æã€RMAå’Œå…¨éƒ¨å®Œæˆçš„é¢œè‰²æ–¹æ¡ˆ
    color_scale_with_engineering = alt.Scale(
        domain=['æœªå¼€å§‹', 'è¿›è¡Œä¸­', 'å·²å®Œæˆ', 'å·¥ç¨‹åˆ†æ', 'RMA', 'å…¨éƒ¨å®Œæˆ'],
        range=['#D3D2D2', '#E84445', '#074166', '#CC011F', '#6FDCB5', '#2ecc71']  # æµ…ç°ã€çº¢è‰²ã€æ·±ç°ã€çº¢è‰²ã€é’ç»¿è‰²ã€ç»¿è‰²
    )
    
    # æ ‡è®°æµ‹è¯•ç«™åˆ«ï¼ˆç”¨äºXè½´æ ‡ç­¾é¢œè‰²æ ‡è¯†ï¼‰
    test_stations = ['è€¦åˆæµ‹è¯•', 'NAæµ‹è¯•', 'Preæµ‹è¯•', 'ä½æ¸©å­˜å‚¨åæµ‹è¯•', 
                     'é«˜æ¸©å­˜å‚¨åæµ‹è¯•', 'postæµ‹è¯•', 'å°ç›–æµ‹è¯•']
    gantt_df['æ˜¯å¦æµ‹è¯•ç«™åˆ«'] = gantt_df['ç«™åˆ«'].apply(lambda x: 'æµ‹è¯•ç«™åˆ«' if x in test_stations else 'æ™®é€šç«™åˆ«')
    
    # åˆ›å»ºç»Ÿä¸€çš„çƒ­åŠ›å›¾
    base_chart = alt.Chart(gantt_df).mark_rect(
        stroke='white',
        strokeWidth=0.5
    ).encode(
        x=alt.X('ç«™åˆ«:N', 
                title='ç«™åˆ«',
                sort=all_stations_sorted,
                axis=alt.Axis(
                    labelAngle=-90, 
                    labelLimit=200,
                    labelColor=alt.expr(
                        f"datum.label == 'è€¦åˆæµ‹è¯•' || datum.label == 'NAæµ‹è¯•' || "
                        f"datum.label == 'Preæµ‹è¯•' || datum.label == 'ä½æ¸©å­˜å‚¨åæµ‹è¯•' || datum.label == 'é«˜æ¸©å­˜å‚¨åæµ‹è¯•' || "
                        f"datum.label == 'postæµ‹è¯•' || datum.label == 'å°ç›–æµ‹è¯•' ? '#CC011F' : 'black'"
                    )
                )),
        y=alt.Y('å£³ä½“å·:N', 
                title='å£³ä½“å·',
                sort=alt.EncodingSortField(field='å£³ä½“æ’åºåºå·', order='descending')),
        color=alt.Color('æ˜¾ç¤ºçŠ¶æ€:N',
                       scale=color_scale_with_engineering,
                       legend=alt.Legend(title='çŠ¶æ€', orient='top')),
        tooltip=[
            alt.Tooltip('å£³ä½“å·:N', title='å£³ä½“å·'),
            alt.Tooltip('ç«™åˆ«:N', title='ç«™åˆ«'),
            alt.Tooltip('ç«™åˆ«æ—¶é—´:N', title='æ—¶é—´'),
            alt.Tooltip('æ˜¾ç¤ºçŠ¶æ€:N', title='çŠ¶æ€')
        ]
    ).properties(
        width=1200,
        height=max(400, len(progress_df) * 30),
        title='æ¨¡å—è¿›åº¦ç”˜ç‰¹å›¾'
    )
    
    chart = base_chart
    
    chart = chart.configure_axis(
        labelFontSize=11,
        titleFontSize=13,
        labelColor='black',
        titleColor='black'
    ).configure_title(
        fontSize=16,
        anchor='start',
        color='black'
    ).configure_view(
        strokeWidth=0
    ).configure_scale(
        bandPaddingInner=0,
        bandPaddingOuter=0
    )
    
    return chart

def create_progress_table(progress_df: pd.DataFrame) -> pd.DataFrame:
    """åˆ›å»ºè¿›åº¦è¡¨æ ¼"""
    table_data = []
    
    for _, row in progress_df.iterrows():
        part_number = row.get('æ–™å·', '')
        stations = get_stations_for_part(part_number)
        current_station = row.get('å½“å‰ç«™ç‚¹', '')
        is_engineering = row.get('æ˜¯å¦å·¥ç¨‹åˆ†æ', False)
        
        # å¦‚æœæ˜¯å·¥ç¨‹åˆ†æï¼Œæ·»åŠ å·¥ç¨‹åˆ†æç«™åˆ«
        if is_engineering:
            stations.append('å·¥ç¨‹åˆ†æ')
        
        # è·å–å½“å‰ç«™ç‚¹çš„åºå·ï¼ˆç”¨äºæ’åºå’Œè®¡ç®—å·²å®Œæˆç«™åˆ«æ•°ï¼‰
        station_order = -1
        completed_count = 0
        
        if is_engineering:
            # å·¥ç¨‹åˆ†æï¼šæ ¹æ®ä¸Šä¸€ç«™è®¡ç®—å·²å®Œæˆç«™åˆ«æ•°
            last_station = row.get('ä¸Šä¸€ç«™', '')
            last_station_normalized = normalize_station_name(last_station)
            if last_station_normalized and last_station_normalized in stations:
                station_order = stations.index(last_station_normalized)
                completed_count = station_order + 1  # åŒ…æ‹¬ä¸Šä¸€ç«™
        elif current_station == "å·²å®Œæˆ":
            # å·²å®Œæˆï¼šæ‰€æœ‰ç«™åˆ«éƒ½å·²å®Œæˆ
            station_order = len(stations) - 1  # æœ€åä¸€ä¸ªç«™åˆ«çš„ç´¢å¼•
            completed_count = len(stations)  # æ‰€æœ‰ç«™åˆ«éƒ½å®Œæˆ
        elif current_station and current_station in stations:
            # æ­£å¸¸æƒ…å†µï¼šå½“å‰ç«™ç‚¹ä¹‹å‰çš„éƒ½æ˜¯å·²å®Œæˆ
            station_order = stations.index(current_station)
            completed_count = station_order  # å½“å‰ç«™ç‚¹ä¹‹å‰çš„ç«™åˆ«æ•°
        else:
            # æ²¡æœ‰å½“å‰ç«™ç‚¹ä¿¡æ¯ï¼Œä½¿ç”¨å®Œæˆæ—¶é—´è®°å½•
            completed_count = len(row['å®Œæˆç«™åˆ«'])
        
        total_count = len(stations)
        progress_pct = (completed_count / total_count * 100) if total_count > 0 else 0
        
        # è·å–æœ€æ–°å®Œæˆç«™åˆ«ï¼ˆå½“å‰ç«™ç‚¹çš„å‰ä¸€ä¸ªï¼‰
        last_completed_station = ''
        if station_order > 0:
            last_completed_station = stations[station_order - 1]
        elif row['å®Œæˆç«™åˆ«']:
            last_completed_station = row['å®Œæˆç«™åˆ«'][-1]
        
        table_data.append({
            'å£³ä½“å·': row['å£³ä½“å·'],
            'æ–™å·': part_number,
            'ç”Ÿäº§è®¢å•': row.get('ç”Ÿäº§è®¢å•', ''),
            'å½“å‰ç«™ç‚¹': current_station,
            'å·²å®Œæˆç«™åˆ«æ•°': completed_count,
            'æ€»ç«™åˆ«æ•°': total_count,
            'å®Œæˆè¿›åº¦': f"{progress_pct:.1f}%",
            'æœ€æ–°å®Œæˆç«™åˆ«': last_completed_station,
            'æ˜¯å¦å·¥ç¨‹åˆ†æ': 'æ˜¯' if is_engineering else 'å¦',
            'ç«™åˆ«åºå·': station_order  # ç”¨äºæ’åºçš„éšè—åˆ—
        })
    
    result_df = pd.DataFrame(table_data)
    # æŒ‰ç«™åˆ«åºå·æ’åºï¼ˆä»å°åˆ°å¤§ï¼Œè¿›åº¦æ…¢çš„åœ¨å‰ï¼‰
    result_df = result_df.sort_values('ç«™åˆ«åºå·', ascending=True)
    # åˆ é™¤æ’åºç”¨çš„åˆ—
    result_df = result_df.drop(columns=['ç«™åˆ«åºå·'])
    
    return result_df

# Streamlit é¡µé¢
st.set_page_config(page_title="æ¨¡å—è¿›åº¦", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š æ¨¡å—WIPè¿›åº¦")

st.markdown(
    """
    <style>
    .stMultiSelect div[data-baseweb="select"] > div {
        flex-wrap: wrap;
    }
    .stMultiSelect [data-baseweb="tag"] {
        max-width: none !important;
        min-width: 260px !important;
        width: fit-content !important;
        display: inline-flex !important;
        align-items: center !important;
        justify-content: space-between !important;
        flex: 0 0 auto !important;
        gap: 6px !important;
    }
    .stMultiSelect [data-baseweb="tag"] > * {
        max-width: none !important;
        flex: 1 1 auto !important;
    }
    .stMultiSelect [data-baseweb="tag-text"] {
        max-width: none !important;
        flex: 1 1 auto !important;
    }
    .stMultiSelect [data-baseweb="tag-text"] span {
        max-width: none !important;
        white-space: nowrap !important;
        overflow: visible !important;
        text-overflow: clip !important;
    }
    .stMultiSelect [data-baseweb="tag"] p {
        white-space: nowrap !important;
        overflow: visible !important;
    }
    .custom-order-tags {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        margin-top: 6px;
    }
    .custom-order-tag {
        background-color: #ff5a5f;
        color: #ffffff;
        padding: 4px 14px;
        border-radius: 10px;
        font-weight: 600;
        letter-spacing: 0.5px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
st.markdown("---")

# åˆå§‹åŒ– session_state
if 'progress_df' not in st.session_state:
    st.session_state.progress_df = None
if 'progress_raw_df' not in st.session_state:
    st.session_state.progress_raw_df = None
if 'uploaded_filename' not in st.session_state:
    st.session_state.uploaded_filename = None

# æ·»åŠ æ•°æ®æºé€‰æ‹©ï¼ˆé»˜è®¤ä»æ–‡ä»¶å¤¹é€‰æ‹©ï¼‰
if 'progress_data_source' not in st.session_state:
    st.session_state.progress_data_source = "ğŸ“ ä»æ–‡ä»¶å¤¹é€‰æ‹©"

data_source = st.radio(
    "é€‰æ‹©æ•°æ®æº",
    options=["ğŸ“ ä»æ–‡ä»¶å¤¹é€‰æ‹©", "ğŸ“¤ ä¸Šä¼ æ–‡ä»¶"],
    index=0,  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆä»æ–‡ä»¶å¤¹é€‰æ‹©ï¼‰
    horizontal=True,
    key="progress_data_source"
)

uploaded_file = None
selected_file_path = None

if data_source == "ğŸ“¤ ä¸Šä¼ æ–‡ä»¶":
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ åŒ…å«å£³ä½“è¿›åº¦ä¿¡æ¯çš„æ–‡ä»¶",
        type=['csv', 'xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«å£³ä½“å·å’Œå„ç«™åˆ«æ—¶é—´ä¿¡æ¯çš„ Excel æˆ– CSV æ–‡ä»¶"
    )
    
    # å¦‚æœä¸Šä¼ äº†æ–°æ–‡ä»¶ï¼Œæ›´æ–° session_state
    if uploaded_file is not None and (st.session_state.uploaded_filename != uploaded_file.name):
        # è§£ææ–‡ä»¶å¹¶ä¿å­˜åˆ° session_state
        with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶..."):
            df = parse_uploaded_file(uploaded_file)
        
        if df is not None:
            st.session_state.progress_raw_df = df
            st.session_state.progress_df = extract_progress_data(df)
            st.session_state.uploaded_filename = uploaded_file.name
            st.success(f"âœ… æ–‡ä»¶è§£ææˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")

else:  # ä»æ–‡ä»¶å¤¹é€‰æ‹©

    col_path, col_refresh = st.columns([4, 1])
    with col_path:
        folder_path = st.text_input(
            "æ–‡ä»¶å¤¹è·¯å¾„",
            value=DEFAULT_DATA_FOLDER,
            placeholder=f"é»˜è®¤: {DEFAULT_DATA_FOLDER}",
            key="progress_folder_path"
        )
    with col_refresh:
        st.markdown("<div style='margin-top: 32px;'></div>", unsafe_allow_html=True)
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°", width='stretch')
    
    if folder_path:
        try:
            search_path = resolve_input_path(folder_path)
            if search_path.exists() and search_path.is_dir():
                # æŸ¥æ‰¾ Excel å’Œ CSV æ–‡ä»¶
                excel_files = list(search_path.glob("*.xlsx")) + list(search_path.glob("*.xls"))
                csv_files = list(search_path.glob("*.csv"))
                all_files = sorted(excel_files + csv_files, key=lambda x: x.stat().st_mtime, reverse=True)
                
                # ç­›é€‰åŒ…å«"å…‰è€¦WIPæŠ¥è¡¨"çš„æ–‡ä»¶
                wip_files = [f for f in all_files if any(keyword in f.name or keyword.lower() in f.name.lower() for keyword in WIP_REPORT_KEYWORDS)]
                
                if all_files:
                    # å¦‚æœæ‰¾åˆ°å…‰è€¦WIPæŠ¥è¡¨æ–‡ä»¶ï¼Œä¼˜å…ˆæ˜¾ç¤º
                    display_files = wip_files if wip_files else all_files
                    
                    # åˆ›å»ºæ–‡ä»¶é€‰æ‹©ä¸‹æ‹‰æ¡†
                    file_options = {f"{f.name} ({f.stat().st_size / 1024:.1f} KB)": str(f) for f in display_files}
                    
                    # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆæœ€æ–°çš„å…‰è€¦WIPæŠ¥è¡¨ï¼‰
                    default_index = 0
                    
                    selected_file_display = st.selectbox(
                        "é€‰æ‹©æ–‡ä»¶" + (" (å·²ç­›é€‰å…‰è€¦WIPæŠ¥è¡¨)" if wip_files else ""),
                        options=list(file_options.keys()),
                        index=default_index,
                        key="progress_file_select"
                    )
                    
                    if selected_file_display:
                        selected_file_path = file_options[selected_file_display]
                        
                        # è‡ªåŠ¨åŠ è½½æœ€æ–°çš„å…‰è€¦WIPæŠ¥è¡¨ï¼ˆä»…åœ¨é¦–æ¬¡åŠ è½½æ—¶ï¼‰
                        auto_load = False
                        if st.session_state.progress_df is None and wip_files and selected_file_display == list(file_options.keys())[0]:
                            auto_load = True
                        
                        # æ·»åŠ åŠ è½½æŒ‰é’®
                        load_btn = st.button("ğŸ“‚ åŠ è½½é€‰ä¸­çš„æ–‡ä»¶", type="primary")
                        
                        if load_btn or auto_load:
                            with st.spinner(f"æ­£åœ¨åŠ è½½ {Path(selected_file_path).name}..."):
                                try:
                                    if selected_file_path.endswith('.csv'):
                                        df = pd.read_csv(selected_file_path)
                                    else:
                                        df = pd.read_excel(selected_file_path)
                                    
                                    st.session_state.progress_raw_df = df
                                    st.session_state.progress_df = extract_progress_data(df)
                                    st.session_state.uploaded_filename = Path(selected_file_path).name
                                    st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")
                                    if auto_load:
                                        st.rerun()
                                except Exception as e:
                                    st.error(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
                else:
                    st.warning(f"åœ¨ `{search_path}` ä¸­æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
            else:
                st.error(f"è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶å¤¹: {search_path}")
        except ValueError as value_error:
            st.error(str(value_error))
        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")

# ä½¿ç”¨ session_state ä¸­çš„æ•°æ®
if st.session_state.progress_df is not None:
    progress_df = st.session_state.progress_df
    df = st.session_state.progress_raw_df
    # å…¼å®¹æ—§ç‰ˆ session_stateï¼šå¦‚æœç¼ºå°‘ç”Ÿäº§è®¢å•åˆ—æˆ–å±æ€§ï¼Œåˆ™é‡æ–°ç”Ÿæˆ
    if (
        progress_df is not None
        and df is not None
        and (
            'ç”Ÿäº§è®¢å•' not in progress_df.columns
            or "production_order_column" not in progress_df.attrs
        )
    ):
        progress_df = extract_progress_data(df)
        st.session_state.progress_df = progress_df
    preview_df = df
    production_order_column = progress_df.attrs.get("production_order_column")
    
    if len(progress_df) > 0:
        filtered_progress_df = progress_df.copy()
        selected_order_values = None
        selected_orders_display: List[str] = []

        with st.container():
            if 'ç”Ÿäº§è®¢å•' in filtered_progress_df.columns:
                order_series = (
                    filtered_progress_df['ç”Ÿäº§è®¢å•']
                    .dropna()
                    .astype(str)
                    .str.strip()
                )
                order_series = order_series[order_series != ""]
                order_options = sorted(order_series.unique().tolist())
                
                if order_options:
                    selected_orders = st.multiselect(
                        "ç”Ÿäº§è®¢å•",
                        options=order_options,
                        default=order_options,
                        key="progress_production_orders",
                    )
                    selected_orders_display = selected_orders or []
                    if selected_orders_display:
                        selected_order_values = {
                            order.strip() for order in selected_orders_display
                        }
                        filtered_progress_df = filtered_progress_df[
                            filtered_progress_df['ç”Ÿäº§è®¢å•']
                            .fillna("")
                            .astype(str)
                            .str.strip()
                            .isin(selected_order_values)
                        ]
                    else:
                        selected_order_values = set()
                        filtered_progress_df = filtered_progress_df.iloc[0:0]
                else:
                    st.multiselect(
                        "ç”Ÿäº§è®¢å•",
                        options=[],
                        default=[],
                        key="progress_production_orders",
                    )
                    st.caption("æœªæ£€æµ‹åˆ°ç”Ÿäº§è®¢å•æ•°æ®")
            else:
                st.info("å½“å‰æ•°æ®ç¼ºå°‘ç”Ÿäº§è®¢å•åˆ—")
        
        if selected_order_values is not None:
            if production_order_column and df is not None and production_order_column in df.columns:
                preview_series = (
                    df[production_order_column]
                    .fillna("")
                    .astype(str)
                    .str.strip()
                )
                if selected_order_values:
                    preview_df = df[preview_series.isin(selected_order_values)]
                else:
                    preview_df = df.iloc[0:0]
            elif not selected_order_values:
                preview_df = df.iloc[0:0]
        
        if filtered_progress_df.empty:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´ç”Ÿäº§è®¢å•é€‰æ‹©ã€‚")
        else:
            st.caption('å½“å‰ç­›é€‰ç»“æœå·²ç¼“å­˜ï¼Œå¯åœ¨â€œæ•°æ®åˆ†æâ€é¡µç»Ÿä¸€ä¿å­˜ã€‚')

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å£³ä½“æ€»æ•°", len(filtered_progress_df))
            with col2:
                avg_progress = filtered_progress_df['å®Œæˆç«™åˆ«'].apply(len).mean()
                st.metric("å¹³å‡å®Œæˆç«™åˆ«æ•°", f"{avg_progress:.1f}")
            with col3:
                total_stations = len(BASE_STATIONS)
                st.metric("åŸºç¡€ç«™åˆ«æ•°", total_stations)
            
            counts_df = calculate_station_counts(filtered_progress_df)
            if not counts_df.empty:
                st.markdown("### å„ç«™åˆ«å½“å‰æ•°é‡")
                table_col, chart_col = st.columns([2, 3])
                with table_col:
                    counts_style = counts_df.style.format({"å æ¯”": "{:.1%}"})
                    st.dataframe(counts_style, width='stretch', height=360)
                with chart_col:
                    station_order = counts_df["ç«™åˆ«"].tolist()
                    chart = (
                        alt.Chart(counts_df)
                        .mark_bar()
                        .encode(
                            x=alt.X("æ•°é‡:Q", title="å£³ä½“æ•°é‡"),
                            y=alt.Y("ç«™åˆ«:N", sort=station_order, title="ç«™åˆ«"),
                            tooltip=["ç«™åˆ«", "æ•°é‡", alt.Tooltip("å æ¯”:Q", title="å æ¯”", format=".1%")],
                        )
                    )
                    st.altair_chart(chart, use_container_width=True)
            
            st.markdown("---")
            
            # é€‰é¡¹å¡
            tab1, tab2 = st.tabs(["ğŸ“ˆ ç”˜ç‰¹å›¾", "ğŸ“‹ è¿›åº¦è¡¨æ ¼"])
            
            with tab1:
                with st.spinner("æ­£åœ¨ç”Ÿæˆç”˜ç‰¹å›¾..."):
                    chart = create_gantt_chart(filtered_progress_df)
                    st.altair_chart(chart, use_container_width=True)
                        
            with tab2:
                table_df = create_progress_table(filtered_progress_df)
                
                # ä½¿ç”¨æ ·å¼é«˜äº®å·¥ç¨‹åˆ†æè¡Œ
                def highlight_engineering(row):
                    if row['æ˜¯å¦å·¥ç¨‹åˆ†æ'] == 'æ˜¯':
                        return ['background-color: #ffcccc'] * len(row)
                    return [''] * len(row)
                
                styled_df = table_df.style.apply(highlight_engineering, axis=1)
                st.dataframe(
                    styled_df,
                    width='stretch',
                    height=400
                )
                
                # ä¸‹è½½æŒ‰é’® - ä½¿ç”¨Excelæ ¼å¼é¿å…ç¼–ç é—®é¢˜
                buffer = io.BytesIO()
                try:
                    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                        table_df.to_excel(writer, index=False, sheet_name='è¿›åº¦è¡¨')
                except ImportError:
                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                        table_df.to_excel(writer, index=False, sheet_name='è¿›åº¦è¡¨')
                buffer.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½è¿›åº¦è¡¨æ ¼ (Excel)",
                    data=buffer,
                    file_name=f"å£³ä½“è¿›åº¦_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )


    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å£³ä½“è¿›åº¦æ•°æ®")
        
    # æ˜¾ç¤ºåŸå§‹æ•°æ®é¢„è§ˆ
    with st.expander("ğŸ“„ æŸ¥çœ‹åŸå§‹æ•°æ®"):
        st.dataframe(preview_df.head(20), width='stretch')
    
    # æ·»åŠ æ¸…é™¤æ•°æ®æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å·²ä¸Šä¼ çš„æ•°æ®"):
        st.session_state.progress_df = None
        st.session_state.progress_raw_df = None
        st.session_state.uploaded_filename = None
        st.rerun()
else:
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    st.info("""
    ### ğŸ“– ä½¿ç”¨è¯´æ˜
    
    1. **ä¸Šä¼ æ–‡ä»¶**ï¼šç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸Šä¼ åŒ…å«å£³ä½“è¿›åº¦ä¿¡æ¯çš„ Excel æˆ– CSV æ–‡ä»¶
    2. **æŸ¥çœ‹ç»“æœ**ï¼š
       - ç”˜ç‰¹å›¾ï¼šç›´è§‚å±•ç¤ºæ‰€æœ‰å£³ä½“åœ¨å„ç«™åˆ«çš„è¿›åº¦
       - è¿›åº¦è¡¨æ ¼ï¼šè¯¦ç»†åˆ—å‡ºæ¯ä¸ªå£³ä½“çš„å®Œæˆæƒ…å†µ
    """)
