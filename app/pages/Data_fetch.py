# title: æ•°æ®æå–
"""å£³ä½“æµ‹è¯•æ•°æ®æŸ¥è¯¢ä¸»é¡µé¢ - é‡æ„ä¼˜åŒ–ç‰ˆ"""

import os, sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
import numpy as np, pandas as pd, streamlit as st, altair as alt

# è·¯å¾„è®¾ç½®
_pages_dir = str(Path(__file__).parent)
if _pages_dir not in sys.path: sys.path.insert(0, _pages_dir)
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path: sys.path.insert(0, parent_dir)

# å¯¼å…¥æ¨¡å—
from data_fetch import (
    PLOT_ORDER, SANITIZED_PLOT_ORDER, SANITIZED_ORDER_LOOKUP, STATION_COLORS, DEFAULT_PALETTE,
    OUTPUT_COLUMNS, SHELL_COLUMN, TEST_TYPE_COLUMN, CURRENT_COLUMN, POWER_COLUMN, VOLTAGE_COLUMN,
    EFFICIENCY_COLUMN, LAMBDA_COLUMN, SHIFT_COLUMN, WAVELENGTH_COLD_COLUMN, CURRENT_TOLERANCE,
    MODULE_MODE, CHIP_MODE, CHIP_TEST_CATEGORY, MEASUREMENT_OPTIONS, TEST_CATEGORY_OPTIONS,
    interpret_folder_input, interpret_chip_folder_input, resolve_test_folder,
    find_measurement_file, find_chip_measurement_file, build_chip_measurement_index,
    build_module_measurement_index_cached, extract_lvi_data, extract_rth_data,
    extract_generic_excel, clear_extraction_caches, align_output_columns, merge_measurement_rows,
    ensure_prediction_libs_loaded, build_multi_shell_chart, build_single_shell_dual_metric_chart,
)
from data_fetch.constants import (
    EXTRACTION_STATE_KEY, EXTRACTION_MODE_OPTIONS, EXTRACTION_MODE_LOOKUP, CHIP_SUPPORTED_MEASUREMENTS,
)
from data_fetch.ui_components import (
    show_toast, trigger_scroll_if_needed, render_extraction_results_section,
    parse_folder_entries, parse_current_points, init_session_state,
)
from data_fetch.file_utils import build_chip_measurement_index_cached
from utils.data_cleaning import drop_zero_current


def _exclude_zero_current(df: pd.DataFrame) -> pd.DataFrame:
    """æ’é™¤é›¶ç”µæµæ•°æ®"""
    return drop_zero_current(df, CURRENT_COLUMN, tol=CURRENT_TOLERANCE) if CURRENT_COLUMN in df.columns and not df.empty else df


def do_measurement(entry_id: str, test_category: str, measurement_label: str, file_path: Path,
                   file_mtime: float, multiple_found: bool, context_label: str,
                   current_points: Optional[List[float]], effective_output_columns: List[str]) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªæµ‹é‡æ–‡ä»¶çš„æ•°æ®æå–"""
    try:
        info_parts = [f"æ‰¾åˆ°æ–‡ä»¶: {context_label} -> {file_path.name}"]
        lvi_tuple, rth_tuple = None, None
        
        if measurement_label == "LVI":
            extracted, missing, lvi_full = extract_lvi_data(file_path=file_path, current_points=current_points, mtime=file_mtime)
            extracted, lvi_full = _exclude_zero_current(extracted), _exclude_zero_current(lvi_full)
            if missing: info_parts.append(f"{context_label}: æœªæ‰¾åˆ°ç”µæµç‚¹ {missing}")
            lvi_tuple = (entry_id, test_category, lvi_full, extracted if current_points else None)
        elif measurement_label == "Rth":
            extracted, missing, rth_full = extract_rth_data(file_path=file_path, current_points=current_points, mtime=file_mtime)
            extracted, rth_full = _exclude_zero_current(extracted), _exclude_zero_current(rth_full)
            if missing: info_parts.append(f"{context_label}: æœªæ‰¾åˆ°ç”µæµç‚¹ {missing}")
            baseline = extracted.attrs.get("lambda_baseline_current")
            if baseline and abs(baseline - 2.0) > CURRENT_TOLERANCE:
                info_parts.append(f"{context_label}: æ³¢é•¿shiftåŸºå‡†ä½¿ç”¨ {baseline:.3f}A")
            rth_tuple = (entry_id, test_category, rth_full)
        else:
            extracted = extract_generic_excel(file_path, mtime=file_mtime)
        
        tagged = extracted.copy()
        tagged.insert(0, TEST_TYPE_COLUMN, test_category)
        tagged.insert(0, SHELL_COLUMN, entry_id)
        return {"tagged": align_output_columns(tagged, columns=effective_output_columns),
                "lvi": lvi_tuple, "rth": rth_tuple, "info": info_parts,
                "multiple": multiple_found, "context": context_label, "error": None}
    except Exception as exc:
        return {"tagged": None, "lvi": None, "rth": None, "info": [],
                "multiple": multiple_found, "context": context_label, "error": f"{context_label}: {exc}"}


def _set_analysis_mode(mode: str) -> None:
    """è®¾ç½®åˆ†ææ¨¡å¼"""
    modes = {"single": "show_single_analysis", "multi_power": "show_multi_power",
             "multi_station": "show_multi_station", "boxplot": "show_boxplot"}
    for k, v in modes.items():
        st.session_state[v] = (k == mode)
    st.query_params.update({"section": mode})
    st.session_state.pending_scroll_target = mode


def _render_storage_section(result_df: Optional[pd.DataFrame], extraction_state: Optional[Dict]) -> None:
    """æ¸²æŸ“æ•°æ®å­˜å‚¨åŒºåŸŸï¼ˆä¿å­˜å’ŒåŠ è½½ï¼‰"""
    # Sidebar storage features removed per request
    return


def render_sidebar(result_df: Optional[pd.DataFrame], extraction_state: Optional[Dict]) -> None:
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.title("ğŸ“‘ åŠŸèƒ½å¯¼èˆª")
        st.markdown("---")
        st.markdown("### ğŸ“Š æ•°æ®åˆ†æ")
        
        buttons = [("ğŸ“ˆ å•å£³ä½“åˆ†æ", "single"), ("ğŸ“‰ å¤šå£³ä½“åˆ†æ", "multi_power"),
                   ("ğŸ”„ å¤šç«™åˆ«åˆ†æ", "multi_station"), ("ğŸ“¦ ç®±çº¿å›¾åˆ†æ", "boxplot")]
        for label, mode in buttons:
            if st.button(label, use_container_width=True):
                _set_analysis_mode(mode)


def render_input_form(extraction_mode: str) -> Tuple[bool, bool, str, List[str], List[str], str]:
    """æ¸²æŸ“è¾“å…¥è¡¨å•"""
    is_module = extraction_mode == MODULE_MODE
    folder_label = "å£³ä½“å·æˆ–Ldtdè·¯å¾„" if is_module else "èŠ¯ç‰‡åç§°æˆ–è·¯å¾„"
    folder_help = ("å¯è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªå£³ä½“å·ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¾‹å¦‚ HHD550048ã€‚ä¹Ÿæ”¯æŒç›´æ¥ç²˜è´´å®Œæ•´è·¯å¾„ã€‚"
                   if is_module else "å¯è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªèŠ¯ç‰‡åæˆ–å®Œæ•´è·¯å¾„ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¾‹å¦‚ 2019-12-120240ã€‚")
    meas_opts = list(MEASUREMENT_OPTIONS.keys()) if is_module else [k for k in MEASUREMENT_OPTIONS if k in CHIP_SUPPORTED_MEASUREMENTS]

    with st.form("input_form"):
        folder_input = st.text_area(folder_label, help=folder_help, key=f"folder_input_{extraction_mode}")
        if is_module:
            selected_tests = st.multiselect("é€‰æ‹©æµ‹è¯•ç±»å‹", TEST_CATEGORY_OPTIONS, default=TEST_CATEGORY_OPTIONS, key="module_test_select")
        else:
            selected_tests = [CHIP_TEST_CATEGORY]
            st.info("èŠ¯ç‰‡æ¨¡å¼ä¼šè‡ªåŠ¨é€’å½’æŸ¥æ‰¾æœ€æ–°çš„ LVI / Rth æµ‹è¯•æ–‡ä»¶ã€‚", icon="â„¹ï¸")
        selected_measurements = st.multiselect("é€‰æ‹©æµ‹è¯•æ–‡ä»¶", meas_opts, default=meas_opts, key=f"measurement_select_{extraction_mode}")
        current_input = st.text_input("ç”µæµç‚¹", help="å¯é€‰ï¼Œé»˜è®¤æœ€é«˜ç”µæµç‚¹ã€‚è¾“å…¥ 'a' æˆ– 'A' æå–æ‰€æœ‰ç”µæµç‚¹ã€‚ä¹Ÿå¯è¾“å…¥å•å€¼æˆ–èŒƒå›´ï¼ˆå¦‚ 12~19ï¼‰ã€‚", key=f"current_input_{extraction_mode}")
        c1, c2 = st.columns(2)
        submitted = c1.form_submit_button("ğŸš€ å¼€å§‹æŠ½å–", use_container_width=True)
        force_refresh = c2.form_submit_button("â™»ï¸ å¼ºåˆ¶åˆ·æ–°ç¼“å­˜", use_container_width=True)
    return submitted, force_refresh, folder_input, selected_tests, selected_measurements, current_input


def process_extraction(folder_entries: List[str], selected_tests: List[str], selected_measurements: List[str],
                       current_points: Optional[List[float]], extraction_mode: str,
                       effective_output_columns: List[str]) -> Tuple[List[pd.DataFrame], List[str], List[str], Dict, Dict]:
    """æ‰§è¡Œæ•°æ®æå–å¤„ç†"""
    combined_frames, error_messages, info_messages = [], [], []
    lvi_plot_sources: Dict[Tuple[str, str], Tuple[pd.DataFrame, Optional[pd.DataFrame]]] = {}
    rth_plot_sources: Dict[Tuple[str, str], pd.DataFrame] = {}
    
    total = len(folder_entries)
    entry_label = "å£³ä½“" if extraction_mode == MODULE_MODE else "èŠ¯ç‰‡"
    if total >= 20: st.info(f"{entry_label}æ•°é‡è¾ƒå¤šï¼Œæ­£åœ¨ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿå¤„ç†...")
    
    progress_text, progress_bar, status_text = st.empty(), st.progress(0.0), st.empty()
    progress_text.markdown(f"**æ­£åœ¨å¤„ç† {total} ä¸ª{entry_label}...**")
    workers = max(8, min(32, (os.cpu_count() or 4) * 4))

    def process_module(entry: str):
        results, errors, infos = [], [], []
        try:
            base_path = interpret_folder_input(entry)
            infos.append(f"è§£æè·¯å¾„: {entry} -> {base_path}")
        except ValueError as e:
            return results, [f"{entry}: {e}"], infos
        for test in selected_tests:
            try:
                folder = resolve_test_folder(base_path, test)
                idx = build_module_measurement_index_cached(str(folder), folder.stat().st_mtime)
            except FileNotFoundError as e:
                errors.append(f"{entry}/{test}: {e}"); continue
            for meas in selected_measurements:
                try:
                    fp, multi, mt = find_measurement_file(folder, MEASUREMENT_OPTIONS[meas], index=idx)
                    results.append(do_measurement(entry, test, meas, fp, mt, multi, f"{entry}/{test}/{meas}", current_points, effective_output_columns))
                except (FileNotFoundError, KeyError, ValueError) as e:
                    errors.append(f"{entry}/{test}/{meas}: {e}")
        return results, errors, infos

    def process_chip(entry: str):
        results, errors, infos = [], [], []
        try:
            folder = interpret_chip_folder_input(entry)
            infos.append(f"è§£æèŠ¯ç‰‡è·¯å¾„: {entry} -> {folder}")
        except (ValueError, FileNotFoundError, NotADirectoryError) as e:
            return results, [f"{entry}: {e}"], infos
        try:
            idx = build_chip_measurement_index(folder)
        except (FileNotFoundError, NotADirectoryError) as e:
            return results, [f"{entry}: {e}"], infos
        for meas in selected_measurements:
            try:
                fp, multi, mt = find_chip_measurement_file(folder, MEASUREMENT_OPTIONS[meas], index=idx)
                results.append(do_measurement(entry, CHIP_TEST_CATEGORY, meas, fp, mt, multi, f"{entry}/{meas}", current_points, effective_output_columns))
            except FileNotFoundError as e:
                errors.append(f"{entry}/{meas}: {e}")
        return results, errors, infos

    with ThreadPoolExecutor(max_workers=workers) as ex:
        proc = process_module if extraction_mode == MODULE_MODE else process_chip
        futures = [ex.submit(proc, e) for e in folder_entries]
    
    for i, fut in enumerate(as_completed(futures), 1):
        res_list, errs, infos = fut.result()
        error_messages.extend(errs); info_messages.extend(infos)
        for res in res_list:
            if res.get("error"): error_messages.append(res["error"])
            else:
                if res.get("tagged") is not None: combined_frames.append(res["tagged"])
                info_messages.extend(res.get("info", []))
                if res.get("multiple"): info_messages.append(f"{res.get('context')}: ä½¿ç”¨æœ€æ–°æ–‡ä»¶")
                if res.get("lvi"): lvi_plot_sources[(res["lvi"][0], res["lvi"][1])] = (res["lvi"][2], res["lvi"][3])
                if res.get("rth"): rth_plot_sources[(res["rth"][0], res["rth"][1])] = res["rth"][2]
        progress_bar.progress(i / max(1, total)); status_text.text(f"å·²å®Œæˆ {i}/{total} ä¸ª{entry_label}")
    
    progress_bar.empty(); progress_text.empty(); status_text.empty()
    return combined_frames, error_messages, info_messages, lvi_plot_sources, rth_plot_sources


def finalize_result_df(combined_frames: List[pd.DataFrame], effective_output_columns: List[str]) -> Optional[pd.DataFrame]:
    """æ•´ç†æœ€ç»ˆç»“æœ DataFrame"""
    if not combined_frames: return None
    
    valid = [f.dropna(how="all").loc[:, lambda x: ~x.isna().all()] for f in combined_frames if not f.empty]
    valid = [f for f in valid if not f.empty]
    if not valid: return None
    
    df = pd.concat(valid, ignore_index=True)
    if EFFICIENCY_COLUMN in df.columns:
        df[EFFICIENCY_COLUMN] = pd.to_numeric(df[EFFICIENCY_COLUMN], errors="coerce").multiply(100).round(3)
    
    df = merge_measurement_rows(df, columns=effective_output_columns)
    
    for col in [CURRENT_COLUMN, POWER_COLUMN, VOLTAGE_COLUMN, EFFICIENCY_COLUMN, LAMBDA_COLUMN, SHIFT_COLUMN]:
        if col in df.columns: df[col] = pd.to_numeric(df[col], errors="coerce").round(3)
    
    if TEST_TYPE_COLUMN in df.columns:
        df[TEST_TYPE_COLUMN] = pd.Categorical(df[TEST_TYPE_COLUMN], categories=PLOT_ORDER, ordered=True)
        sort_cols = [TEST_TYPE_COLUMN] + ([CURRENT_COLUMN] if CURRENT_COLUMN in df.columns else [])
        if CURRENT_COLUMN in df.columns: df[CURRENT_COLUMN] = pd.to_numeric(df[CURRENT_COLUMN], errors="coerce")
        df = df.sort_values(by=sort_cols, kind="stable")
        df[TEST_TYPE_COLUMN] = df[TEST_TYPE_COLUMN].astype("object").str.replace("æµ‹è¯•", "", regex=False)
    return df


def _extract_metric_series(df: pd.DataFrame, cols: List[str]) -> Optional[pd.DataFrame]:
    """æå–å¹¶æ¸…æ´—æŒ‡æ ‡æ•°æ®"""
    if df is None or df.empty: return None
    sub = df.dropna(subset=cols)
    if sub.empty: return None
    numeric = sub[cols].apply(pd.to_numeric, errors="coerce").dropna()
    return numeric if not numeric.empty else None


def render_multi_power_analysis(lvi_plot_sources: Dict, rth_plot_sources: Dict) -> None:
    """æ¸²æŸ“å¤šå£³ä½“åŠŸç‡åˆ†æ"""
    st.markdown('<div id="multi_power"></div>', unsafe_allow_html=True)
    trigger_scroll_if_needed("multi_power")
    st.subheader("å¤šå£³ä½“åˆ†æ")
    
    shells = sorted({s for s, _ in lvi_plot_sources.keys()})
    if not shells: show_toast("è¯·å…ˆæŠ½å–æ•°æ®", icon="âš ï¸"); return
    if len(shells) > 10: show_toast(f"å¤šå£³ä½“åˆ†ææœ€å¤šæ”¯æŒ10ä¸ªå£³ä½“ï¼Œå½“å‰æœ‰{len(shells)}ä¸ª", icon="âš ï¸"); return
    
    power_entries, eff_entries, lambda_entries = [], [], []
    for test in PLOT_ORDER:
        p_series, e_series, l_series = [], [], []
        for sid in shells:
            data = lvi_plot_sources.get((sid, test))
            if data:
                df_full = data[0]
                if (p := _extract_metric_series(df_full, [CURRENT_COLUMN, POWER_COLUMN])) is not None: p_series.append((sid, p))
                if (e := _extract_metric_series(df_full, [CURRENT_COLUMN, EFFICIENCY_COLUMN])) is not None: e_series.append((sid, e))
            rth = rth_plot_sources.get((sid, test))
            if (l := _extract_metric_series(rth, [CURRENT_COLUMN, LAMBDA_COLUMN])) is not None: l_series.append((sid, l))
        if p_series: power_entries.append((test, p_series))
        if e_series: eff_entries.append((test, e_series))
        if l_series: lambda_entries.append((test, l_series))
    
    if not any([power_entries, eff_entries, lambda_entries]):
        st.info("æ‰€é€‰å£³ä½“åœ¨åŠŸç‡ã€æ•ˆç‡å’Œæ³¢é•¿æ•°æ®ä¸Šç¼ºå°‘å¯å¯¹æ¯”çš„ç«™åˆ«ã€‚"); return
    
    tabs = ["åŠŸç‡å¯¹æ¯”", "æ•ˆç‡å¯¹æ¯”"] + (["æ³¢é•¿å¯¹æ¯”"] if lambda_entries else [])
    main_tabs = st.tabs(tabs)
    with main_tabs[0]: _render_metric_comparison_tabs(power_entries, POWER_COLUMN, "åŠŸç‡(W)", "power")
    with main_tabs[1]:
        eff_pct = [(t, [(s, n.assign(**{EFFICIENCY_COLUMN: n[EFFICIENCY_COLUMN]*100})) for s, n in series]) for t, series in eff_entries]
        _render_metric_comparison_tabs(eff_pct, EFFICIENCY_COLUMN, "ç”µå…‰æ•ˆç‡(%)", "eff")
    if lambda_entries:
        with main_tabs[2]: _render_metric_comparison_tabs(lambda_entries, LAMBDA_COLUMN, "æ³¢é•¿(nm)", "lambda")


def _render_metric_comparison_tabs(tab_entries: List[Tuple[str, List]], metric_column: str, metric_label: str, key_prefix: str) -> None:
    """æ¸²æŸ“æŒ‡æ ‡å¯¹æ¯”æ ‡ç­¾é¡µ"""
    if not tab_entries: st.info(f"æ‰€é€‰å£³ä½“åœ¨{metric_label}æ•°æ®ä¸Šç¼ºå°‘å¯å¯¹æ¯”çš„ç«™åˆ«ã€‚"); return
    tabs = st.tabs([t.replace("æµ‹è¯•", "") for t, _ in tab_entries])
    for tab, (test, series) in zip(tabs, tab_entries):
        with tab:
            chart = build_multi_shell_chart(series, metric_column, metric_label, test)
            if chart:
                st.altair_chart(chart, theme="streamlit", use_container_width=True)
            else:
                st.info("æ— æ³•ç”Ÿæˆå¯¹æ¯”å›¾è¡¨")


def render_single_analysis(extraction_state: Dict, lvi_plot_sources: Dict) -> None:
    """æ¸²æŸ“å•å£³ä½“åˆ†æ"""
    st.markdown('<div id="single"></div>', unsafe_allow_html=True)
    trigger_scroll_if_needed("single")
    
    if not extraction_state: show_toast("è¯·å…ˆæŠ½å–æ•°æ®åå†è¿›è¡Œåˆ†æ", icon="âš ï¸"); return
    entries = extraction_state["folder_entries"]
    if len(entries) != 1: show_toast("å•å£³ä½“åˆ†æä»…æ”¯æŒå•ä¸ªå£³ä½“å·ï¼Œè¯·è°ƒæ•´è¾“å…¥", icon="âš ï¸"); return
    
    shell_id = entries[0]
    st.subheader("ç”µæµ-åŠŸç‡-ç”µå…‰æ•ˆç‡æ›²çº¿")
    
    available = []
    for test in PLOT_ORDER:
        data = lvi_plot_sources.get((shell_id, test))
        if not data or data[0] is None or data[0].empty: continue
        plot_df = data[0].dropna(subset=[CURRENT_COLUMN, POWER_COLUMN, EFFICIENCY_COLUMN])
        if not plot_df.empty: available.append((test, data[0], data[1], plot_df))
    
    if not available: show_toast("æœªæ‰¾åˆ°å¯ç”¨äºç»˜åˆ¶çš„ç«™åˆ«æ•°æ®", icon="âš ï¸"); return
    
    tabs = st.tabs([e[0].replace("æµ‹è¯•", "") for e in available])
    plotted = False
    for tab, (test, df_full, df_sel, plot_df) in zip(tabs, available):
        with tab:
            chart = build_single_shell_dual_metric_chart(plot_df, df_sel, shell_id, test)
            if chart:
                st.altair_chart(chart, theme="streamlit", use_container_width=True)
                plotted = True
            else:
                st.info("æ— æ³•ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨")
    if not plotted: show_toast("æœªæ‰¾åˆ°å¯ç»˜åˆ¶çš„ LVI æ•°æ®", icon="âš ï¸")


def _compute_station_changes(avg_df: pd.DataFrame, ordered_types: List[str]) -> List[Dict]:
    """è®¡ç®—ç«™åˆ«é—´å˜åŒ–"""
    changes = []
    metrics = [(POWER_COLUMN, "åŠŸç‡å˜åŒ–(W)", 1), (EFFICIENCY_COLUMN, "æ•ˆç‡å˜åŒ–(%)", 100),
               (VOLTAGE_COLUMN, "ç”µå‹å˜åŒ–(V)", 1), (LAMBDA_COLUMN, "æ³¢é•¿å˜åŒ–(nm)", 1), (SHIFT_COLUMN, "Shiftå˜åŒ–(nm)", 1)]
    for i in range(len(ordered_types) - 1):
        f_type, t_type = ordered_types[i], ordered_types[i + 1]
        f_row, t_row = avg_df[avg_df[TEST_TYPE_COLUMN] == f_type], avg_df[avg_df[TEST_TYPE_COLUMN] == t_type]
        if f_row.empty or t_row.empty: continue
        row = {"å˜åŒ–": f"{f_type} -> {t_type}"}
        for col, name, mult in metrics:
            if col in avg_df.columns:
                fv, tv = f_row[col].iloc[0] * mult, t_row[col].iloc[0] * mult
                if pd.notna(fv) and pd.notna(tv): row[name] = tv - fv
        changes.append(row)
    return changes


def render_multi_station_analysis(lvi_plot_sources: Dict, rth_plot_sources: Dict, extraction_state: Dict) -> None:
    """æ¸²æŸ“å¤šç«™åˆ«åˆ†æ"""
    if not lvi_plot_sources: st.info("è¯·å…ˆæŠ½å–æ•°æ®"); return
    
    st.markdown('---')
    st.markdown('<div id="multi_station"></div>', unsafe_allow_html=True)
    trigger_scroll_if_needed("multi_station")
    st.subheader("ğŸ“Š å¤šç«™åˆ«åˆ†æ")

    shells = sorted({s for s, _ in lvi_plot_sources.keys()})
    
    if len(shells) > 1:
        st.markdown("**ğŸ“Š æ‰€æœ‰å£³ä½“å¹³å‡å€¼å˜åŒ–åˆ†æ**")
        all_data = []
        for sid in shells:
            for (s, test), (df, _) in lvi_plot_sources.items():
                if s == sid and df is not None and not df.empty:
                    tmp = df.assign(**{TEST_TYPE_COLUMN: test.replace("æµ‹è¯•", ""), SHELL_COLUMN: sid})
                    all_data.append(tmp)
        
        if rth_plot_sources and isinstance(rth_plot_sources, dict):
            for i, df in enumerate(all_data):
                sid, test = df[SHELL_COLUMN].iloc[0], df[TEST_TYPE_COLUMN].iloc[0]
                rth = rth_plot_sources.get((sid, test + "æµ‹è¯•"))
                if rth is None or (isinstance(rth, pd.DataFrame) and rth.empty):
                    rth = rth_plot_sources.get((sid, test))
                if rth is not None and isinstance(rth, pd.DataFrame) and not rth.empty:
                    rth_tmp = rth.assign(**{TEST_TYPE_COLUMN: test, SHELL_COLUMN: sid})
                    cols = [CURRENT_COLUMN, TEST_TYPE_COLUMN, SHELL_COLUMN] + [c for c in [LAMBDA_COLUMN, SHIFT_COLUMN] if c in rth_tmp.columns]
                    all_data[i] = pd.merge(df, rth_tmp[cols], on=[CURRENT_COLUMN, TEST_TYPE_COLUMN, SHELL_COLUMN], how="outer")
        
        if all_data:
            combined = pd.concat(all_data, ignore_index=True)
            agg = {c: 'mean' for c in [POWER_COLUMN, EFFICIENCY_COLUMN, VOLTAGE_COLUMN, LAMBDA_COLUMN, SHIFT_COLUMN] if c in combined.columns}
            avg = combined.groupby(TEST_TYPE_COLUMN).agg(agg).reset_index()
            ordered = [t for t in SANITIZED_PLOT_ORDER if t in avg[TEST_TYPE_COLUMN].unique()]
            changes = _compute_station_changes(avg, ordered)
            
            if changes:
                df_changes = pd.DataFrame(changes)
                num_cols = [c for c in df_changes.columns if c != "å˜åŒ–"]
                for c in num_cols:
                    df_changes[c] = df_changes[c].apply(lambda v: 0.0 if pd.notna(v) and abs(round(v, 3)) < 0.001 else round(v, 3) if pd.notna(v) else v)
                
                unit_map = {"(W)": "W", "(%)": "%", "(V)": "V", "(nm)": "nm"}
                for _, row in df_changes.iterrows():
                    st.markdown(f"**{row['å˜åŒ–']}**")
                    cols = st.columns(len(num_cols))
                    for i, col in enumerate(num_cols):
                        if col in row and pd.notna(row[col]):
                            unit = next((u for k, u in unit_map.items() if k in col), "")
                            label = col.replace(f"({unit})", "").strip() if unit else col
                            cols[i].metric(label=label, value=f"{abs(row[col]):.3f}{unit}", delta=f"{row[col]:+.3f}{unit}", delta_color="normal")
                    st.markdown("---")
        st.markdown("---")

    # æŒ‡æ ‡åˆ†æ
    result_df = extraction_state.get("result_df") if extraction_state else None
    metrics = [POWER_COLUMN, VOLTAGE_COLUMN, EFFICIENCY_COLUMN, LAMBDA_COLUMN, SHIFT_COLUMN]
    avail_metrics = [c for c in metrics if result_df is not None and c in result_df.columns]
    
    if result_df is None or result_df.empty: st.info("æ— å¯ç”¨æ•°æ®"); return
    
    per_type_records = []
    if avail_metrics and TEST_TYPE_COLUMN in result_df.columns:
        for test, grp in result_df.groupby(TEST_TYPE_COLUMN):
            for col in avail_metrics:
                s = pd.to_numeric(grp[col], errors="coerce").dropna()
                if not s.empty:
                    per_type_records.append({"ç«™åˆ«": test, "æŒ‡æ ‡": col, "æ•°é‡": int(s.count()),
                        "å‡å€¼": round(s.mean(), 3), "ä¸­ä½æ•°": round(s.median(), 3),
                        "æ ‡å‡†å·®": round(s.std(ddof=1), 3) if s.count() > 1 else 0.0,
                        "æœ€å°å€¼": round(s.min(), 3), "æœ€å¤§å€¼": round(s.max(), 3)})
    
    if avail_metrics:
        with st.expander("ğŸ“Š æŒ‡æ ‡åˆ†æ", expanded=True):
            test_types = [t for t in SANITIZED_PLOT_ORDER if TEST_TYPE_COLUMN in result_df.columns and t in result_df[TEST_TYPE_COLUMN].unique()]
            opts = ["å…¨éƒ¨"] + test_types if test_types else ["å…¨éƒ¨"]
            sel = st.selectbox("é€‰æ‹©ç«™åˆ«è¿›è¡Œç»Ÿè®¡", opts, index=len(opts)-1, key="stats_test_type_select")
            
            data = result_df if sel == "å…¨éƒ¨" else result_df[result_df[TEST_TYPE_COLUMN] == sel]
            st.markdown(f"### ğŸ“ˆ {'å…¨éƒ¨' if sel == 'å…¨éƒ¨' else sel + ' ç«™'}æ•°æ®ç»Ÿè®¡")
            
            num_data = data[avail_metrics].apply(pd.to_numeric, errors="coerce")
            summary = pd.DataFrame({"æ•°é‡": num_data.notna().sum().astype("Int64"), "å‡å€¼": num_data.mean(),
                "ä¸­ä½æ•°": num_data.median(), "æ ‡å‡†å·®": num_data.std(ddof=1).fillna(0.0),
                "æœ€å°å€¼": num_data.min(), "æœ€å¤§å€¼": num_data.max()})
            for c in ["å‡å€¼", "ä¸­ä½æ•°", "æ ‡å‡†å·®", "æœ€å°å€¼", "æœ€å¤§å€¼"]: summary[c] = summary[c].round(3)
            summary.index.name = "æŒ‡æ ‡"
            st.dataframe(summary.style.format({c: "{:.3f}" for c in ["å‡å€¼", "ä¸­ä½æ•°", "æ ‡å‡†å·®", "æœ€å°å€¼", "æœ€å¤§å€¼"]}), use_container_width=True)
    else:
        st.info("æŒ‰ç«™åˆ«ç»Ÿè®¡ç¼ºå°‘æœ‰æ•ˆçš„æ•°å€¼åˆ—")
    
    if per_type_records:
        with st.expander("ğŸ“‹ æŒ‰ç«™åˆ«è¯¦ç»†ç»Ÿè®¡", expanded=False):
            df = pd.DataFrame(per_type_records)[["ç«™åˆ«", "æŒ‡æ ‡", "æ•°é‡", "å‡å€¼", "ä¸­ä½æ•°", "æ ‡å‡†å·®", "æœ€å°å€¼", "æœ€å¤§å€¼"]]
            for metric in df["æŒ‡æ ‡"].unique():
                mdata = df[df["æŒ‡æ ‡"] == metric].drop(columns=["æŒ‡æ ‡"]).assign(__o=lambda x: x["ç«™åˆ«"].map(SANITIZED_ORDER_LOOKUP)).sort_values("__o").drop(columns=["__o"]).set_index("ç«™åˆ«")
                st.markdown(f"#### ğŸ”¹ {metric}")
                st.dataframe(mdata.style.format({"å‡å€¼": "{:.3f}", "ä¸­ä½æ•°": "{:.3f}", "æ ‡å‡†å·®": "{:.3f}", "æœ€å°å€¼": "{:.3f}", "æœ€å¤§å€¼": "{:.3f}"}), use_container_width=True)
                if len(mdata) > 1:
                    c1, c2 = st.columns(2)
                    c1.caption("å‡å€¼å¯¹æ¯”"); c1.bar_chart(mdata["å‡å€¼"], use_container_width=True)
                    c2.caption("æ ‡å‡†å·®å¯¹æ¯”"); c2.bar_chart(mdata["æ ‡å‡†å·®"], use_container_width=True)


def _filter_by_current(df: pd.DataFrame, currents: List[float]) -> pd.DataFrame:
    """æŒ‰ç”µæµç‚¹è¿‡æ»¤æ•°æ®"""
    if df is None or df.empty or CURRENT_COLUMN not in df.columns: return df
    if currents:
        mask = pd.Series(False, index=df.index)
        for c in currents: mask |= (df[CURRENT_COLUMN] - c).abs() <= CURRENT_TOLERANCE
        filtered = df.loc[mask]
        if not filtered.empty: return filtered
    max_c = df[CURRENT_COLUMN].max()
    return df.loc[(df[CURRENT_COLUMN] - max_c).abs() <= CURRENT_TOLERANCE] if pd.notna(max_c) else df


def render_boxplot_analysis(lvi_plot_sources: Dict, rth_plot_sources: Dict, extraction_state: Dict) -> None:
    """æ¸²æŸ“ç®±çº¿å›¾åˆ†æ"""
    if not lvi_plot_sources: st.info("è¯·å…ˆæŠ½å–æ•°æ®"); return
    
    st.markdown('---')
    st.markdown('<div id="boxplot"></div>', unsafe_allow_html=True)
    trigger_scroll_if_needed("boxplot")
    st.subheader("ğŸ“Š ç®±çº¿å›¾åˆ†æ")

    currents = (extraction_state.get("current_points", []) or []) if extraction_state else []
    
    # æ”¶é›† LVI æ•°æ®
    all_data = []
    for (sid, test), (df_full, df_sel) in lvi_plot_sources.items():
        if df_full is None or df_full.empty or CURRENT_COLUMN not in df_full.columns: continue
        base = df_sel if df_sel is not None and not df_sel.empty else _filter_by_current(df_full, currents)
        if not base.empty:
            all_data.append(base.assign(**{TEST_TYPE_COLUMN: test.replace("æµ‹è¯•", ""), SHELL_COLUMN: sid}))
    
    if not all_data: st.info("æ— å¯ç”¨æ•°æ®"); return
    combined = pd.concat(all_data, ignore_index=True)
    
    # åˆå¹¶ Rth æ•°æ®
    if rth_plot_sources:
        rth_list = []
        for (sid, test), rth in rth_plot_sources.items():
            if rth is None or rth.empty or CURRENT_COLUMN not in rth.columns: continue
            filtered = _filter_by_current(rth, currents)
            if not filtered.empty:
                tmp = filtered.assign(**{TEST_TYPE_COLUMN: test.replace("æµ‹è¯•", ""), SHELL_COLUMN: sid})
                cols = [SHELL_COLUMN, TEST_TYPE_COLUMN, CURRENT_COLUMN] + [c for c in [LAMBDA_COLUMN, SHIFT_COLUMN] if c in tmp.columns]
                rth_list.append(tmp[cols])
        if rth_list:
            rth_combined = pd.concat(rth_list, ignore_index=True)
            combined = combined.drop(columns=[c for c in [LAMBDA_COLUMN, SHIFT_COLUMN] if c in combined.columns], errors='ignore')
            combined = pd.merge(combined, rth_combined, on=[SHELL_COLUMN, TEST_TYPE_COLUMN, CURRENT_COLUMN], how="outer")

    # æ¸²æŸ“ç®±çº¿å›¾
    has_lambda = LAMBDA_COLUMN in combined.columns and combined[LAMBDA_COLUMN].notna().any()
    has_shift = SHIFT_COLUMN in combined.columns and combined[SHIFT_COLUMN].notna().any()
    tabs = ["åŠŸç‡", "æ•ˆç‡", "ç”µå‹"] + (["æ³¢é•¿"] if has_lambda else []) + (["æ³¢é•¿Shift"] if has_shift else [])
    box_tabs = st.tabs(tabs)
    
    configs = [(POWER_COLUMN, "åŠŸç‡(W)", None), (EFFICIENCY_COLUMN, "æ•ˆç‡(%)", lambda s: pd.to_numeric(s, errors="coerce") * 100),
               (VOLTAGE_COLUMN, "ç”µå‹(V)", None)]
    if has_lambda: configs.append((LAMBDA_COLUMN, "æ³¢é•¿(nm)", None))
    if has_shift: configs.append((SHIFT_COLUMN, "æ³¢é•¿Shift(nm)", None))
    
    for tab, (col, label, trans) in zip(box_tabs, configs):
        with tab: _render_boxplot(combined[[TEST_TYPE_COLUMN, col]].copy(), col, label, transform=trans)
    st.markdown('---')


def _render_boxplot(data: pd.DataFrame, value_col: str, value_label: str, transform=None) -> None:
    """æ¸²æŸ“å•ä¸ªç®±çº¿å›¾"""
    if transform: data = data.copy(); data[value_col] = transform(data[value_col])
    data = data.dropna()
    if data.empty: st.info(f"æ— {value_label}æ•°æ®"); return

    counts = data.groupby(TEST_TYPE_COLUMN).size()
    enough = counts[counts >= 2].index.tolist()
    insufficient = counts[counts < 2].index.tolist()
    with_data = [s for s in enough if data[data[TEST_TYPE_COLUMN] == s][value_col].std() > 1e-10]
    no_var = [s for s in enough if s not in with_data]

    if not with_data:
        st.info(f"ä»¥ä¸‹ç«™åˆ«æ•°æ®æ— å˜åŒ–ï¼š{', '.join(no_var)}" if no_var else "å„ç«™åˆ«æ•°æ®ç‚¹ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦ 2 ä¸ªå£³ä½“çš„æ•°æ®ï¼‰")
        return

    filtered = data[data[TEST_TYPE_COLUMN].isin(with_data)].assign(__o=lambda x: x[TEST_TYPE_COLUMN].map(SANITIZED_ORDER_LOOKUP)).sort_values("__o").drop(columns=["__o"])
    stations = [s for s in SANITIZED_PLOT_ORDER if s in with_data] + [s for s in with_data if s not in SANITIZED_PLOT_ORDER]
    colors = [STATION_COLORS.get(s, "#000084") for s in stations]

    chart = alt.Chart(filtered).mark_boxplot(extent="min-max", size=50).encode(
        x=alt.X(f"{TEST_TYPE_COLUMN}:N", title="Station", sort=stations, axis=alt.Axis(labelAngle=-45)),
        y=alt.Y(f"{value_col}:Q", title=value_label, scale=alt.Scale(zero=False)),
        color=alt.Color(f"{TEST_TYPE_COLUMN}:N", legend=None, scale=alt.Scale(domain=stations, range=colors)),
    ).properties(height=500, title=f"å„ç«™åˆ«{value_label}åˆ†å¸ƒç®±çº¿å›¾").configure_title(fontSize=16, anchor="middle")
    st.altair_chart(chart, use_container_width=True)

    if len(stations) > 1 and ensure_prediction_libs_loaded():
        _render_boxplot_statistics(filtered, value_col, stations)

    warns = []
    if insufficient: warns.append(f"æ•°æ®ç‚¹ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦ 2 ä¸ªå£³ä½“ï¼‰ï¼š{', '.join(insufficient)}")
    if no_var: warns.append(f"æ•°æ®æ— å˜åŒ–ï¼š{', '.join(no_var)}")
    if warns: st.caption("âš ï¸ " + "ï¼›".join(warns))


def _render_boxplot_statistics(filtered: pd.DataFrame, value_col: str, stations: List[str]) -> None:
    """æ¸²æŸ“ç®±çº¿å›¾ç»Ÿè®¡åˆ†æ"""
    from data_fetch.models import get_stats_module
    stats_mod = get_stats_module()
    if stats_mod is None: return
    
    results = []
    for i in range(1, len(stations)):
        curr, prev = stations[i], stations[i-1]
        cs, ps = filtered[filtered[TEST_TYPE_COLUMN] == curr][value_col], filtered[filtered[TEST_TYPE_COLUMN] == prev][value_col]
        if cs.empty or ps.empty: continue
        cm, pm = cs.mean(), ps.mean()
        pct = (cm - pm) / abs(pm) * 100 if pm != 0 else np.nan
        try:
            _, pv = stats_mod.ttest_ind(cs, ps, equal_var=False, nan_policy='omit')
            sig = "***" if pv < 0.001 else "**" if pv < 0.01 else "*" if pv < 0.05 else "ns"
        except: pv, sig = np.nan, "N/A"
        results.append({"æ¯”è¾ƒé¡¹": f"{curr} vs {prev}", "å‰åºå‡å€¼": pm, "å½“å‰å‡å€¼": cm, "å˜åŒ–å¹…åº¦(%)": pct, "På€¼": pv, "æ˜¾è‘—æ€§": sig})
    
    if results:
        st.write("#### ğŸ“‰ ç»Ÿè®¡åˆ†æ (T-test)")
        st.caption("æ³¨ï¼šæ˜¾è‘—æ€§æ ‡è®° ***(p<0.001), **(p<0.01), *(p<0.05), ns(æ— æ˜¾è‘—å·®å¼‚)")
        df = pd.DataFrame(results)
        df["å‰åºå‡å€¼"] = df["å‰åºå‡å€¼"].apply(lambda x: f"{x:.4f}")
        df["å½“å‰å‡å€¼"] = df["å½“å‰å‡å€¼"].apply(lambda x: f"{x:.4f}")
        df["å˜åŒ–å¹…åº¦(%)"] = df["å˜åŒ–å¹…åº¦(%)"].apply(lambda x: f"{x:+.2f}%" if pd.notnull(x) else "N/A")
        df["På€¼"] = df["På€¼"].apply(lambda x: f"{x:.4e}" if pd.notnull(x) else "N/A")
        st.table(df)


def _auto_update_zh_database(result_df: pd.DataFrame, folder_entries: List[str], extraction_mode: str) -> None:
    """
    è‡ªåŠ¨æ›´æ–° Zh's DataBase ä¸­å·²å­˜åœ¨çš„å£³ä½“æ•°æ®
    
    å½“ç”¨æˆ·åœ¨ Data_fetch ä¸­æŸ¥è¯¢å£³ä½“æ—¶ï¼Œå¦‚æœè¯¥å£³ä½“å·²å­˜åœ¨äº Zh's DataBase ä¸­ï¼Œ
    åˆ™è‡ªåŠ¨æ›´æ–°å…¶æµ‹è¯•æ•°æ®ã€‚
    """
    if result_df is None or result_df.empty:
        return
    
    if extraction_mode != MODULE_MODE:
        return  # åªå¤„ç†æ¨¡å—æ¨¡å¼
    
    try:
        # åŠ¨æ€å¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        from pages.Data_Manager import check_shell_in_database, update_shell_test_data
        
        updates = []
        for shell_id in folder_entries:
            shell_id = str(shell_id).strip()
            if not shell_id:
                continue
            
            # æ£€æŸ¥å£³ä½“æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
            if not check_shell_in_database(shell_id):
                continue
            
            # è·å–è¯¥å£³ä½“çš„æµ‹è¯•æ•°æ®
            shell_data = result_df[result_df[SHELL_COLUMN] == shell_id] if SHELL_COLUMN in result_df.columns else pd.DataFrame()
            if shell_data.empty:
                continue
            
            # æ”¶é›†æµ‹è¯•æ•°æ®
            test_data = {}
            for col in shell_data.columns:
                if col not in [SHELL_COLUMN, TEST_TYPE_COLUMN]:
                    # å–æœ€æ–°çš„éç©ºå€¼
                    values = shell_data[col].dropna()
                    if not values.empty:
                        test_data[col] = values.iloc[-1]
            
            # è·å–æœ€æ–°ç«™åˆ«
            current_station = None
            if TEST_TYPE_COLUMN in shell_data.columns:
                stations = shell_data[TEST_TYPE_COLUMN].dropna()
                if not stations.empty:
                    current_station = str(stations.iloc[-1])
            
            if test_data:
                updates.append({
                    "shell_id": shell_id,
                    "test_data": test_data,
                    "current_station": current_station
                })
        
        # æ‰§è¡Œæ›´æ–°
        if updates:
            updated_count = 0
            for update in updates:
                if update_shell_test_data(
                    update["shell_id"],
                    update["test_data"],
                    update.get("current_station"),
                    source="data_fetch"
                ):
                    updated_count += 1
            
            if updated_count > 0:
                st.toast(f"âœ… å·²è‡ªåŠ¨æ›´æ–° Zh's DataBase ä¸­ {updated_count} ä¸ªå£³ä½“çš„æµ‹è¯•æ•°æ®", icon="ğŸ—„ï¸")
    
    except ImportError:
        pass  # Data_Manager æ¨¡å—ä¸å¯ç”¨æ—¶é™é»˜å¿½ç•¥
    except Exception as e:
        pass  # æ›´æ–°å¤±è´¥æ—¶é™é»˜å¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹


def main() -> None:
    """ä¸»å‡½æ•°"""
    st.set_page_config(page_title="Excel æ•°æ®åˆ—æå–", layout="wide")
    init_session_state()
    
    state = st.session_state.get(EXTRACTION_STATE_KEY)
    result_df = state["result_df"] if state else None
    render_sidebar(result_df, state)
    
    st.title("å£³ä½“æµ‹è¯•æ•°æ®æŸ¥è¯¢")
    st.caption("æ”¯æŒè¾“å…¥å¤šä¸ªå£³ä½“å·ï¼ŒæŒ‰æµ‹è¯•ç±»å‹ä¸æµ‹è¯•æ–‡ä»¶æ‰¹é‡æå–æ•°æ®ã€‚")
    st.markdown('<div id="input"></div>', unsafe_allow_html=True)

    mode_label = st.radio("æ•°æ®æå–æ¨¡å¼", [l for l, _ in EXTRACTION_MODE_OPTIONS], index=0, horizontal=True, key="data_fetch_mode")
    extraction_mode = EXTRACTION_MODE_LOOKUP.get(mode_label, MODULE_MODE)
    submitted, force_refresh, folder_input, selected_tests, selected_measurements, current_input = render_input_form(extraction_mode)
    
    action = submitted or force_refresh
    entry_label = "å£³ä½“" if extraction_mode == MODULE_MODE else "èŠ¯ç‰‡"
    entry_prompt = "å£³ä½“å·" if extraction_mode == MODULE_MODE else "èŠ¯ç‰‡åæˆ–è·¯å¾„"
    extraction_state = state  # ä½¿ç”¨ä¹‹å‰è·å–çš„ state

    # æ£€æŸ¥è¾“å…¥å˜åŒ–
    inputs_match = extraction_state and "form_folder_input" in extraction_state and all([
        folder_input == extraction_state.get("form_folder_input", ""),
        selected_tests == extraction_state.get("form_selected_tests", []),
        selected_measurements == extraction_state.get("form_selected_measurements", []),
        current_input == extraction_state.get("form_current_input", ""),
        extraction_mode == extraction_state.get("form_mode", MODULE_MODE)
    ])

    if extraction_state and not action and not inputs_match:
        st.session_state[EXTRACTION_STATE_KEY] = extraction_state = None

    if force_refresh:
        clear_extraction_caches()
        for k in [EXTRACTION_STATE_KEY, "lvi_plot_sources", "rth_plot_sources"]: st.session_state.pop(k, None)
        extraction_state, inputs_match = None, False

    recompute = force_refresh or extraction_state is None or (action and not inputs_match)
    if not action and extraction_state is None: st.info("å¡«å†™å‚æ•°åç‚¹å‡»ã€Œå¼€å§‹æå–ã€æŒ‰é’®"); return

    if action:
        for k in ["show_multi_station", "show_boxplot", "show_single_analysis", "show_multi_power"]: st.session_state[k] = False
        st.session_state.pending_scroll_target = None
        
        if not folder_input: st.toast(f"âš ï¸è¯·å¡«å†™{entry_prompt}", icon="âš ï¸"); return
        if extraction_mode == MODULE_MODE and not selected_tests: st.toast("âš ï¸è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæµ‹è¯•ç±»å‹", icon="âš ï¸"); return
        if not selected_measurements: st.toast("âš ï¸è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶", icon="âš ï¸"); return

        folder_entries = parse_folder_entries(folder_input)
        if not folder_entries: st.toast(f"âš ï¸æœªè¯†åˆ«åˆ°æœ‰æ•ˆçš„{entry_label}è¾“å…¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼", icon="âš ï¸"); return

        current_points: Optional[List[float]] = []
        if current_input.strip():
            try: current_points = parse_current_points(current_input)
            except ValueError as e: st.toast(f"âš ï¸{e}", icon="âš ï¸"); return

        if recompute:
            st.session_state.lvi_plot_sources = st.session_state.rth_plot_sources = {}
            out_cols = [c for c in OUTPUT_COLUMNS if not (extraction_mode == MODULE_MODE and c == WAVELENGTH_COLD_COLUMN)]
            
            frames, errors, infos, lvi_src, rth_src = process_extraction(folder_entries, selected_tests, selected_measurements, current_points, extraction_mode, out_cols)
            st.session_state.lvi_plot_sources, st.session_state.rth_plot_sources = lvi_src, rth_src
            
            result_df = finalize_result_df(frames, out_cols)
            if result_df is None:
                st.toast("âŒ æœªèƒ½æ±‡æ€»å‡ºä»»ä½•æ•°æ®", icon="âŒ")
                if errors:
                    with st.expander(f"å¤±è´¥è¯¦æƒ…ï¼ˆ{len(errors)} æ¡ï¼‰", expanded=False):
                        for m in errors: st.markdown(f"- {m}")
                st.session_state[EXTRACTION_STATE_KEY] = None; return

            st.session_state[EXTRACTION_STATE_KEY] = extraction_state = {
                "folder_entries": folder_entries, "combined_frames": frames, "error_messages": errors,
                "info_messages": infos, "result_df": result_df, "current_points": current_points,
                "form_folder_input": folder_input, "form_selected_tests": selected_tests,
                "form_selected_measurements": selected_measurements, "form_current_input": current_input, "form_mode": extraction_mode,
            }
            
            # è‡ªåŠ¨æ›´æ–° Zh's DataBase ä¸­å·²å­˜åœ¨çš„å£³ä½“æ•°æ®
            _auto_update_zh_database(result_df, folder_entries, extraction_mode)
    else:
        result_df, errors, infos = extraction_state["result_df"], extraction_state["error_messages"], extraction_state["info_messages"]

    render_extraction_results_section(st.container(), result_df, extraction_state.get("error_messages", []), extraction_state.get("info_messages", []), entity_label=entry_label)
    lvi_src, rth_src = st.session_state.get('lvi_plot_sources', {}), st.session_state.get('rth_plot_sources', {})

    if st.session_state.get('show_multi_power'): render_multi_power_analysis(lvi_src, rth_src)
    if st.session_state.get('show_multi_station'): render_multi_station_analysis(lvi_src, rth_src, extraction_state)
    if st.session_state.get('show_boxplot'): render_boxplot_analysis(lvi_src, rth_src, extraction_state)
    if st.session_state.get('show_single_analysis'): render_single_analysis(extraction_state, lvi_src)


if __name__ == "__main__":
    main()
